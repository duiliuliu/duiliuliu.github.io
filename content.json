{"meta":{"title":"Duiliuliu","subtitle":null,"description":"随笔","author":"duiliu","url":"http://duiliuliu.github.io","root":"/"},"pages":[{"title":"about","date":"2018-03-10T07:33:42.000Z","updated":"2019-03-03T03:17:32.101Z","comments":true,"path":"about/index.html","permalink":"http://duiliuliu.github.io/about/index.html","excerpt":"","text":"most time sleep , wake up occasionally to code ! 个人信息 github email 简历 本站信息 2018-03-10 博客简单建立 2018-04-14 更新主页展示博客最新文章与github仓库 2018-05-06 更新主页展示博客最新文章及其摘要 2018-05-16 更新主页展示增加rss订阅 2018-06-12 更新博文自动生成目录导航 2019-02-10 迁移至hexo，使用主题Theme-BMW,增加侧边栏点击缩进、增加代码高亮 2019-02-13 增加站内搜索"},{"title":"tags","date":"2018-03-10T07:32:53.000Z","updated":"2019-03-02T10:35:54.685Z","comments":true,"path":"tags/index.html","permalink":"http://duiliuliu.github.io/tags/index.html","excerpt":"","text":""},{"title":"categories","date":"2018-03-10T07:33:24.000Z","updated":"2019-03-02T10:35:54.684Z","comments":true,"path":"categories/index.html","permalink":"http://duiliuliu.github.io/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"更新过程中的查询","slug":"更新过程中的查询","date":"2019-01-19T16:00:00.000Z","updated":"2019-03-03T14:52:35.115Z","comments":true,"path":"2019/01/20/更新过程中的查询/","link":"","permalink":"http://duiliuliu.github.io/2019/01/20/更新过程中的查询/","excerpt":"记载项目过程中的思考","text":"记载项目过程中的思考 项目问题思考我们需要对每天的活跃用户进行划分群体(外部群体数据导入，ETL按照一定规则进行划分)，然后给其他需求方(如数据分析部、运营部、算法部等等)提供数据服务， 123数据化运营用户画像 全球76亿人口中约2/3拥有手机，半数为 智能型设备 服务细分 千人千面日志分析 埋点日志/日志采集/日志分析 我们的元数据是 odps(阿里云提供的大数据计算平台) 宽表，以及外部数据导入 在系统架构设计中，遇到以下问题： 底层架构初始问题： 存储使用什么？ MYSQL，目前该表大概有2亿条数据，之后在人群来源更多了之后，数据增长会更快，mysql应该是吃不消的。 ADS(阿里云ADB)，继续使用ADS，这个是可以的，目前的解决方案也是在saas那个ads的库中。因为只同步一天的人群即可，所以不需要担心数据量的增长， 但是同步到ADS中，稳定性是受ADS的影响的，目前来看ADS的稳定性并不是很能够得到保障，还有就是单独开一个ADS的库，成本也稍微高一些。 ES：使用ES直接存储人群关系的话，存储为一个index，两个fileld，无法按tagId字段删除。 存储数据格式设计为什么样的？ 我们的业务需求是提供 /user/tags 这个接口的稳定对外服务，qps达到400-500 可以直接存储 userid，tagid的对应关系，也可以直接存储userid，tagidList的对应关系。 前者是直接存储人群;后者是需要在olap计算好用户和分群集合的对应关系，然后再进行存储。（这种应该是不提倡的，因为olap的稳定性和速度都没有办法保证，如果这么做的话和直接将查询落在olap上没有区别） 对外接口的数据存储定下来之后，olap中的分群变化后，如何去做数据同步到对外接口库？ 那么为什么需要数据的同步呢 人群的生成和变动最终都会落在olap库中，查询的接口使用的存储中的数据并不是实时更新的，所以需要从olap库中去同步这部分的更新数据。 olap中的数据每天分为初始化和变动两个部分 初始化：odps→ads用户宽表，规则动态分群更新，静态分群+自定义分群拷贝t-1，同步etl人群+圈选人群的生成的规则人群。 变动：创建规则分群+同步etl人群+同步圈选规则人群 做数据同步，可以以人群为粒度，每一个人群拆分成一个任务，交给EOS去执行同步，需要考虑的是上游只需要将任务拆分丢弃给EOS系统即可，失败重试，幂等性由EOS系统的任务保证。 用户群新增更新操作时,此时如何保证查询到有效的数据 数据同步更新时，如何保证查询到有效的数据 分群的存储和删除? 比如很快的新建分群，然后删除分群，同步是分布式任务，很可能先到达删除任务，在到达新建任务，此时如何处理 数据化运营 DAU(Daily Active User)日活跃用户数量。常用于反映网站、互联网应用或网络游戏的运营情况。DAU 通常统计一日（统计日）之内，登录或使用了某个产品的用户数（去除重复登录的用户），这与流量统计工具里的访客（UV）概念相似。 通常 DAU 会结合 MAU（月活跃用户数量）一起使用，这两个指标一般用来衡量服务的用户粘性以及服务的衰退周期。 [1] MAU、DAU 分别从宏观和微观的角度对服务的用户粘性做了权衡，也可以这么说，MAU 更像战略层面的表征，DAU 更像战术层面的表征。通过这些宏观和细微的趋势变化，可以对营销及推广提供一些数据支持或者帮助。 假如有一个近来不景气的电商平台，平台日活从年初 50 万一路下跌，到了现在，剩下 40 万底裤，也就两条路可走了1.老板绞尽脑汁去哄着投资人2.老板勒紧裤带过日子(员工就更不好过了) 这个时候老板那可以做什么呢？BD、市场、运营会如何做呢： “谈几家合作平台，互换资源搞些流量？” “投几个内容 KOL(关键意见领袖，如大 V)，或者投点广告主？” “加做几场促销吧，配合 Push 能涨点日活” 捞回老客 流失老客召回一定比拉新成本更低，更精准，流量质量更好。 这个时候我们可以针对老客户做运营，简单而有效的挺过难关 对于捞老客户，运营可以这样做 方法： 推送消息 ： 网站私信/短信/邮件…. 在我们的日常中，这种营销很常见，而且现在的大平台会做一些精准话的营销，比如构建用户画像，分群，针对群体特点进行推送广告或者优惠信息！ 搞活动： 促销优惠 赠送优惠券 商品领取 回归免费领礼品 – 事实证明 这一事件很容易拉回老客户 社交裂变 数据化运营 数据支撑 群体划分 群体特征模型 数据反馈 响应数据 漏斗分析假设我们在今日头条投放了一则广告，一段时间内，1000 人点击了广告，200 人点击后进行了注册，50 人注册后根据提示下载了 APP，最后只有 10 人在 APP 完成了消费转化。 在这里，从 1000 到 10，就是一个简单的漏斗。任何一个活动，从触达后用户的首个特定动作发生到最终的转化，就是一个漏斗。漏斗展示了一次活动的直接成效，并将成效分解到各个步骤，为结果提供每个层次的归因 裂变数据饿了么式的红包分享、拼多多式的助力砍价，还是每日优鲜的 0 元吃水果、携程的助力抢车票，亦或是近期朋友圈现象级的网易荣格心理测试、连咖啡的“我的咖啡店”，这些教科书级的活动或玩法，不论转化导向或传播导向，都是围绕“社交”这个价值点展开的 价值追踪 对于新加入的用户，又可以继续追踪他们的日常行为进行进一步分析，为后续分分析提供支持 知乎 | 用户类型 | 用户行为 | 价值 || ————– | ———————- | —————————- || 一般内容消费者 | 没事刷知乎，只看不说话 | 消费主体与流量主题，人多 || 传播互动型用户 | 点赞/评论/分享/转发 | 碎片内容生产，传播 || 知识付费者 | 购买会员或live私家课 | 核心内容消费者，重要收入 || 一般内容生产者 | 80%内容生产 | 内容生态的基石，大v的绿叶 || 大V | 头部内容的生产 | 20%的内容带来80%的流量与收入 | - 成本评估 - 有效的活动可以继续","categories":[{"name":"项目","slug":"项目","permalink":"http://duiliuliu.github.io/categories/项目/"}],"tags":[{"name":"项目","slug":"项目","permalink":"http://duiliuliu.github.io/tags/项目/"},{"name":"问题","slug":"问题","permalink":"http://duiliuliu.github.io/tags/问题/"}]},{"title":"Java 时间格式化","slug":"Java时间格式化","date":"2019-01-14T16:00:00.000Z","updated":"2019-03-02T11:29:49.810Z","comments":true,"path":"2019/01/15/Java时间格式化/","link":"","permalink":"http://duiliuliu.github.io/2019/01/15/Java时间格式化/","excerpt":"对于Java中simpleDateFormat类，在多线程使用中会有隐患，这儿我们推荐使用joda time库，简洁好用无隐患","text":"对于Java中simpleDateFormat类，在多线程使用中会有隐患，这儿我们推荐使用joda time库，简洁好用无隐患 Java 时间格式化业务： 需要对时间戳格式的数据进行转化为固定时间格式的数据。 simpleDateFormat 在多线程情况下不安全，而且 joda_time 还支持格式化的时间加减算法，所以推荐使用 joda_time SimpleDateFormatSimpleDateFormat 是 Java 中非常常用的一个类，该类用来对日期字符串进行解析和格式化输出，但如果使用不小心会导致非常微妙和难以调试的问题，因为 DateFormat 和 SimpleDateFormat 类不都是线程安全的，在多线程环境下调用 format() 和 parse() 方法应该使用同步代码来避免问题。 123SimpleDateFormat simpleDateFormat = new SimpleDateFormat(DATE_FORMAT);System.out.println(simpleDateFormat.format(new Date(System.currentTimeMillis()))); 对于 SimpleDateFormat 非线程安全的解决– 可用 threadlocal 将 SimpleDateFormat 维护在线程的本地变量中，就不会发生线程安全问题了，不过会有耗费资源的问题 12345678910111213private static ThreadLocal&lt;SimpleDateFormat&gt; formatThreadlocal;public static SimpleDateFormat getFormat()&#123; if (formatThreadlocal.get() == null) &#123; SimpleDateFormat simpleDateFormat = new SimpleDateFormat(DATE_FORMAT); formatThreadlocal.set(simpleDateFormat); return simpleDateFormat; &#125;else&#123; //③直接返回线程本地变量 return formatThreadlocal.get(); &#125;&#125; joda_time1new DateTime(System.currentTimeMillis()).toString(DATE_FORMAT);","categories":[{"name":"Java","slug":"Java","permalink":"http://duiliuliu.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://duiliuliu.github.io/tags/Java/"},{"name":"joda","slug":"joda","permalink":"http://duiliuliu.github.io/tags/joda/"}]},{"title":"mybatis参数","slug":"mybatis参数","date":"2019-01-13T16:00:00.000Z","updated":"2019-03-03T15:13:13.982Z","comments":true,"path":"2019/01/14/mybatis参数/","link":"","permalink":"http://duiliuliu.github.io/2019/01/14/mybatis参数/","excerpt":"","text":"mybatis 中#与\\$这两个都为字符串替换，用来替换变量拼接 SQL. 一般能用#的就别用$. MyBatis排序时使用order by 动态参数时需要注意，用$而不是# #将传入的数据当做一个字符串处理#将传入的数据都当成一个字符串，会对自动传入的数据加一个双引号。 如：order by #user_id#，如果传入的值是 111,那么解析成 sql 时的值为 order by &quot;111&quot;, 如果传入的值是 id，则解析成的 sql 为 order by &quot;id&quot;. #方式能够很大程度防止sql注入。 \\$将传入的数据直接显示生成在 SQL 中\\$将传入的数据直接显示生成在sql中。如：order by $user_id$，如果传入的值是111,那么解析成sql时的值为order by user_id, 如果传入的值是id，则解析成的sql为order by id. #方式能够很大程度防止sql注入。","categories":[{"name":"Java","slug":"Java","permalink":"http://duiliuliu.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://duiliuliu.github.io/tags/Java/"},{"name":"mybatis","slug":"mybatis","permalink":"http://duiliuliu.github.io/tags/mybatis/"}]},{"title":"gitlabci自动化打包上传UDF","slug":"gitlabci自动化打包上传UDF","date":"2019-01-07T16:00:00.000Z","updated":"2019-03-02T11:53:13.003Z","comments":true,"path":"2019/01/08/gitlabci自动化打包上传UDF/","link":"","permalink":"http://duiliuliu.github.io/2019/01/08/gitlabci自动化打包上传UDF/","excerpt":"gitlab-cicd工具，将提交的代码自动化打包并上传到服务器，需要配置docker","text":"gitlab-cicd工具，将提交的代码自动化打包并上传到服务器，需要配置docker 编写 udf idea 安装 MaxCompute Studio 插件 本地安装 插件库安装 创建 projectnew -&gt; project -&gt; MaxCompute Studio 创建 modulenew -&gt; Module -&gt; Maxcompute Java 编写 Java 类src/main/java 包上 new -&gt; Maxcompute Java 类继承 UDF 主要方法 evaluate() 上传 udf docker 中运行： 所以需要一个 docker 镜像，镜像中有 maven 环境，有 odps 客户端可以上传 udf maven 打包 udf 为可执行 jar mvn clean package 然后使用 odps 客户端推送 jar 到 odps 上 需要有 odps 客户端，安装： 12345678910centos : sudo yum -y install odpscmdUbuntu : sudo apt-get -y install odpscmd修改配置 ~/.odpscmd/odps_config.ini project_name=&lt;project_name&gt; access_id=&lt;accessid&gt; access_key=&lt;accesskey&gt; end_point=http://service.odps.aliyun.com/api tunnel_endpoint=http://dt.odps.aliyun.com log_view_host=http://logview.odps.aliyun.com https_check=true 然后使用 odps 客户端推送 jarodps 连接需要 12odpscmdadd jar UDFGetJsonID.jar 创建函数 CREATE FUNCTION UDFGetJsonID AS com.qunhe.bigdata.UDFGetJsonID USING UDFGetJsonID.jar 配置 gitlabci (配置 .gitlab-ci.yml) 1234567891011121314151617181920212223242526272829303132333435363738394041image: registry.xxx.com/datax/udf_uploadstages:- build- uploadbefore_script:- source /etc/profile- MOUDLE_NAME=$(ls -R | grep &apos;.*/src/&apos; | awk &apos;&#123;FS=&quot;/&quot;&#125; &#123;print $2&#125;&apos; | sed -n &apos;1,2p&apos;)- UDF_LIST_STR=$(ls -R | grep &apos;.*\\.java&apos;)- UDF_LIST_STR=$&#123;UDF_LIST_STR//.java/&#125;cache:paths: - ./*/target/*.jarbuild:stage: buildtags: - kube-runnerscript: - cd $MOUDLE_NAME - mvn clean packageonly: - masterupload:stage: uploadtags: - kube-runnerscript: - JAR_NAME=$(ls -R | grep &apos;.*\\.jar&apos;) - odpscmd -e &quot;add jar $MOUDLE_NAME/target/$JAR_NAME -f&quot; - OLD_IFS=&quot;$IFS&quot; - IFS=&quot; &quot; - UDF_LIST=($UDF_LIST_STR) - IFS=&quot;$OLD_IFS&quot; - for var in $&#123;UDF_LIST[@]&#125;; do odpscmd -e &quot;DROP FUNCTION $var&quot; ; done - for var in $&#123;UDF_LIST[@]&#125;; do odpscmd -e &quot;CREATE FUNCTION $var AS $var USING $JAR_NAME&quot; ; doneonly: - master 遇到的问题 udf 编写 docker 镜像建立 push 公共仓库直接 push；私有仓库需要先标记名称 dockerfile 与 RUN commit udf 上传 配置文件中非 script 作用域中，不能使用 shell 变量 文件与函数会重复，所以文件需要覆盖，而函数没有覆盖选项，所以将函数先行删除在注册函数 相关文档 JAVA UDF 开发 odps 资源操作 odps 函数操作 使用.gitlab-ci.yml 配置作业","categories":[{"name":"工具","slug":"工具","permalink":"http://duiliuliu.github.io/categories/工具/"}],"tags":[{"name":"gitlab CI/CD","slug":"gitlab-CI-CD","permalink":"http://duiliuliu.github.io/tags/gitlab-CI-CD/"},{"name":"自动化","slug":"自动化","permalink":"http://duiliuliu.github.io/tags/自动化/"}]},{"title":"elasticsearch入门","slug":"2018-07-25-elasticsearch入门","date":"2018-07-24T16:00:00.000Z","updated":"2019-03-02T11:29:36.727Z","comments":true,"path":"2018/07/25/2018-07-25-elasticsearch入门/","link":"","permalink":"http://duiliuliu.github.io/2018/07/25/2018-07-25-elasticsearch入门/","excerpt":"本文仅是记录入门","text":"本文仅是记录入门 elasticsearch入门 入门单个 Elastic 实例称为一个节点（node）。一组节点构成一个集群（cluster）。 Elastic 数据管理的顶层单位就叫做 Index（索引）。它是单个数据库的同义词。每个 Index （即数据库）的名字必须是小写。 下面的命令可以查看当前节点的所有 Index。 $ curl -X GET ‘http://localhost:9200/_cat/indices?v&#39; 下面的命令可以列出每个 Index 所包含的 Type。 $ curl ‘localhost:9200/_mapping?pretty=true’ _cat命令查看状态查看所有索引 _cat/indies?v```123456_cat命令可以查看elasticsearch状态* verbose每个命令都支持？v参数，来显示详细信息 $ curl localhost:9200/_cat/master?vid host ip nodeQG6QrX32QSi8C3-xQmrSoA 127.0.0.1 127.0.0.1 Manslaughter1234* help每个命令都支持使用help参数，来输出可以显示的列： GET _cat/master?helpid | | node idhost | h | host nameip | | ip addressnode | n | node name 1234* headers通过h参数，可以指定输出字段 GET /_cat/master?vid host ip nodeQG6QrX32QSi8C3-xQmrSoA 127.0.0.1 127.0.0.1 Manslaughter GET /_cat/master?h=host,ip,node127.0.0.1 127.0.0.1 Manslaughter123456#### `索引增删`新建 Index，可以直接向 Elastic 服务器发出 PUT 请求。下面的例子是新建一个名叫weather的 Index。```PUT /weather 服务器返回一个 JSON 对象，里面的acknowledged字段表示操作成功。 1234&#123; &quot;acknowledged&quot;:true, &quot;shards_acknowledged&quot;:true&#125; 查看weather索引信息 1234567891011121314151617181920GET weather&#123; &quot;weather&quot;: &#123; &quot;aliases&quot;: &#123;&#125;, &quot;mappings&quot;: &#123;&#125;, &quot;settings&quot;: &#123; &quot;index&quot;: &#123; &quot;creation_date&quot;: &quot;1532482584126&quot;, &quot;number_of_shards&quot;: &quot;5&quot;, &quot;number_of_replicas&quot;: &quot;1&quot;, &quot;uuid&quot;: &quot;2tl4hhjRS4Cj3fD475p5JQ&quot;, &quot;version&quot;: &#123; &quot;created&quot;: &quot;5040099&quot; &#125;, &quot;provided_name&quot;: &quot;weather&quot; &#125; &#125; &#125;&#125; 其中，number_of_replicas 是数据备份数，如果只有一台机器，设置为0；number_of_shards 是数据分片数，默认为5，有时候设置为3 获取设置信息 12345678910#获取weather的设置GET weather/_settings#获取所有的设置GET _all/_settings#获取所有的设置(同上)GET _settings#获取weather和accounts的设置GET weather,accounts/_settings 修改副本数量： 1234PUT weather/_settings&#123; &quot;number_of_replicas&quot;: 2&#125; 新增记录向指定的 /Index/Type 发送 PUT 请求，就可以在 Index 里面新增一条记录。比如，向/accounts/person发送请求，就可以新增一条人员记录。 12345PUT accounts/job/1&#123; &quot;user&quot;:&quot;王二麻&quot;, &quot;title&quot;:&quot;系统分析师&quot; &#125; 服务器返回的 JSON 对象，会给出 Index、Type、Id、Version 等信息。 123456789&#123; &quot;_index&quot;:&quot;accounts&quot;, &quot;_type&quot;:&quot;person&quot;, &quot;_id&quot;:&quot;1&quot;, &quot;_version&quot;:1, &quot;result&quot;:&quot;created&quot;, &quot;_shards&quot;:&#123;&quot;total&quot;:2,&quot;successful&quot;:1,&quot;failed&quot;:0&#125;, &quot;created&quot;:true&#125; 新增记录的时候，也可以不指定 Id，这时要改成 POST 请求。 123456POST /accounts/job&#123; &quot;user&quot;: &quot;李四&quot;, &quot;title&quot;: &quot;工程师&quot;, &quot;desc&quot;: &quot;系统管理&quot;&#125;&apos; 服务器返回的 JSON 对象里面，_id字段就是一个随机字符串。 123456789&#123; &quot;_index&quot;:&quot;accounts&quot;, &quot;_type&quot;:&quot;person&quot;, &quot;_id&quot;:&quot;AV3qGfrC6jMbsbXb6k1p&quot;, &quot;_version&quot;:1, &quot;result&quot;:&quot;created&quot;, &quot;_shards&quot;:&#123;&quot;total&quot;:2,&quot;successful&quot;:1,&quot;failed&quot;:0&#125;, &quot;created&quot;:true&#125; 查询记录使用 GET 方法，直接请求/Index/Type/_search，就会返回所有记录。 123456789#查询该索引下所有文档GET accounts/_searchGET accounts/job/_search查询单个文档GET accounts/job/1GET accounts/job/1?_sourceGET accounts/job/1?_source=title GET accounts/job/1?_source=user,title 查询返回结果中字段含义： 1234567took: 表示该操作的耗时(ms)timeout: 是否超时hits: 表示命中的记录total：返回记录数max_score：最高的匹配程度hits：返回的记录组成的数组。_score: 匹配程度，最高为1.0，默认是按照这个字段降序排列。 全文搜索 Elastic 的查询非常特别，使用自己的查询语法，要求 GET 请求带有数据体。 12345678GET accounts/job/_search&#123; &quot;query&quot;:&#123; &quot;match&quot;: &#123; &quot;desc&quot;: &quot;师&quot; &#125; &#125;&#125; 上面代码使用 Match 查询，指定的匹配条件是desc字段里面包含”师”这个词。返回结果如下: 1234567891011121314151617181920212223242526&#123; &quot;took&quot;: 26, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 1, &quot;max_score&quot;: 0.28582606, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;accounts&quot;, &quot;_type&quot;: &quot;job&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_score&quot;: 0.28582606, &quot;_source&quot;: &#123; &quot;user&quot;: &quot;张三&quot;, &quot;title&quot;: &quot;工程师&quot;, &quot;desc&quot;: &quot;数据管理工程师&quot; &#125; &#125; ] &#125;&#125; Elastic 默认一次返回10条结果，可以通过size字段改变这个设置。 123456789GET accounts/job/_search&#123; &quot;query&quot;:&#123; &quot;match&quot;: &#123; &quot;desc&quot;: &quot;师&quot; &#125; &#125;, &quot;size&quot;:1&#125; 上面代码指定，每次只返回一条结果。 还可以通过from字段，指定位移。 12345678910GET accounts/job/_search&#123; &quot;query&quot;:&#123; &quot;match&quot;: &#123; &quot;desc&quot;: &quot;师&quot; &#125; &#125;, &quot;from&quot;:1, &quot;size&quot;:1&#125; 如果有多个搜索关键字， Elastic 认为它们是or关系 12345678GET accounts/job/_search&#123; &quot;query&quot;:&#123; &quot;match&quot;: &#123; &quot;desc&quot;: &quot;师 shi&quot; &#125; &#125;&#125; 上面代码搜索的是软件 or 系统。 如果要执行多个关键词的and搜索，必须使用布尔查询。 123456789101112131415GET accounts/job/_search&#123; &quot;query&quot;:&#123; &quot;bool&quot;: &#123; &quot;must&quot;: [ &#123;&quot;match&quot;: &#123; &quot;title&quot;: &quot;师&quot; &#125;&#125;, &#123;&quot;match&quot;: &#123; &quot;desc&quot;: &quot;师&quot; &#125;&#125; ] &#125; &#125;&#125; 修改记录 (直接覆盖)123456789101112131415PUT accounts/job/1&#123; &quot;user&quot;:&quot;张三&quot;, &quot;title&quot;:&quot;工程师&quot; , &quot;desc&quot;:&quot;数据管理工程师&quot;&#125;#或者POST accounts/job/AWTPLR57niBd4cuXBYQc/_update&#123; &quot;doc&quot;:&#123; &quot;desc&quot;:&quot;teacher&quot; &#125;&#125; 更新记录后，返回结果中有几个字段发生改变：123&quot;_version&quot; : 2,&quot;result&quot; : &quot;updated&quot;,&quot;created&quot; : false 版本（version）从1变成2，操作类型（result）从created变成updated，created字段变成false，因为这次不是新建记录。 删除记录12345678#删除一条记录(文章),DELETE accounts/job/1#删除一个type(表) es5不再支持删除typeDELETE accounts/job#删除整个 index (库)DELETE accounts","categories":[{"name":"存储","slug":"存储","permalink":"http://duiliuliu.github.io/categories/存储/"}],"tags":[{"name":"搜索引擎","slug":"搜索引擎","permalink":"http://duiliuliu.github.io/tags/搜索引擎/"},{"name":"elasticserach","slug":"elasticserach","permalink":"http://duiliuliu.github.io/tags/elasticserach/"}]},{"title":"Springboot 中使用线程池","slug":"Springboot中使用线程池","date":"2018-07-22T16:00:00.000Z","updated":"2019-03-02T11:30:28.452Z","comments":true,"path":"2018/07/23/Springboot中使用线程池/","link":"","permalink":"http://duiliuliu.github.io/2018/07/23/Springboot中使用线程池/","excerpt":"在spring boot项目中需要使用多线程去请求数据封装为excel二进制返回，做博文以记录","text":"在spring boot项目中需要使用多线程去请求数据封装为excel二进制返回，做博文以记录 Springboot 中使用线程池在很多场景下，我们需要多线程更加快速高效的执行任务，池化资源可以更好地对线程进行管理控制。 如果并发的请求数量非常多，但每个线程执行的时间很短，这样就会频繁的创建和销毁线程，如此一来会大大降低系统的效率。可能出现服务器在为每个请求创建新线程和销毁线程上花费的时间和消耗的系统资源要比处理实际的用户请求的时间和资源更多。 springboot 中提供了简单高效的线程池配置方案。不过我们需要先了解下线程池 Java 线程池java.uitl.concurrent.ThreadPoolExecutor 类是线程池中最核心的一个类 我们来看一下 ThreadPoolExecutor 的具体实现 123456789101112131415public class ThreadPoolExecutor extends AbstractExecutorService &#123; ..... public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue); public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,ThreadFactory threadFactory); public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,RejectedExecutionHandler handler); public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,ThreadFactory threadFactory,RejectedExecutionHandler handler); ...&#125; 可以看到 ThreadPoolExecutor 继承自 AbstractExecutorService，有四个构造器。这四个构造器中有 5 个参数是必须有，有两个是可有可不有的。 这些参数的含义分别是： int corePoolSize 核心池的大小。在创建了线程池后，默认情况下，线程池中并没有任何线程，而是等待有任务到来才创建线程去执行任务，除非调用了 prestartAllCoreThreads()或者 prestartCoreThread()方法，这两个方法从名字可以吧看出，是预创建线程的意思。 默认情况下，在创建了线程池后，线程池中的线程数为 0 ，当有任务来之后，就会创建一个线程去执行任务，当线程池中线程数达到 corePoolSize 后，就会把到达的任务添加进缓冲队列中。 int maximumPoolSize 线程池最大线程数，这个参数也是一个非常重要的参数，它表示在线程池中最多能创建多少个线程； long keepAliveTime 表示非核心线程没有任务执行时最多保持多久时间会终止；默认情况下，是作用于非核心线程的，也就是说，只有当线程池中的线程数大于 corePoolSize 时，keepAliveTime 才会起作用，直到线程池中的线程数不大于 corePoolSize，即当线程池中的线程数大于 corePoolSize 时，如果一个线程空闲的时间达到 keepAliveTime，则会终止，直到线程池中的线程数不超过 corePoolSize。 但是如果调用了 allowCoreThreadTimeOut(boolean)方法，在线程池中的线程数不大于 corePoolSize 时，keepAliveTime 参数也会起作用，直到线程池中的线程数为 0； TimeUnit unit 参数 keepAliveTime 的时间单位，有 7 种取值，在 TimeUnit 类中有 7 种静态属性： TimeUnit.DAYS; //天 TimeUnit.HOURS; //小时 TimeUnit.MINUTES; //分钟 TimeUnit.SECONDS; //秒 TimeUnit.MILLISECONDS; //毫秒 TimeUnit.MICROSECONDS; //微妙 TimeUnit.NANOSECONDS; //纳秒 BlockingQueue workQueue 等待队列，当任务提交时，如果线程池中的线程数量大于等于 corePoolSize 的时候，把该任务封装成一个 Worker 对象放入等待队列； 当提交一个新的任务到线程池以后, 线程池会根据当前线程池中正在运行着的线程的数量来决定对该任务的处理方式，主要有以下几种处理方式(排队策略): 直接提交 这种方式常用的队列是 SynchronousQueue，但现在还没有研究过该队列，这里暂时还没法介绍； 使用无界队列 一般使用基于链表的阻塞队列 LinkedBlockingQueue。如果使用这种方式，那么线程池中能够创建的最大线程数就是 corePoolSize，而 maximumPoolSize 就不会起作用了（后面也会说到）。当线程池中所有的核心线程都是 RUNNING 状态时，这时一个新的任务提交就会放入等待队列中 使用有界队列 一般使用 ArrayBlockingQueue。使用该方式可以将线程池的最大线程数量限制为 maximumPoolSize，这样能够降低资源的消耗，但同时这种方式也使得线程池对线程的调度变得更困难，因为线程池和队列的容量都是有限的值，所以要想使线程池处理任务的吞吐率达到一个相对合理的范围，又想使线程调度相对简单，并且还要尽可能的降低线程池对资源的消耗，就需要合理的设置这两个数量 如果要想降低系统资源的消耗（包括 CPU 的使用率，操作系统资源的消耗，上下文环境切换的开销等）, 可以设置较大的队列容量和较小的线程池容量, 但这样也会降低线程处理任务的吞吐量。 如果提交的任务经常发生阻塞，那么可以考虑通过调用 setMaximumPoolSize() 方法来重新设定线程池的容量。 如果队列的容量设置的较小，通常需要将线程池的容量设置大一点，这样 CPU 的使用率会相对的高一些。但如果线程池的容量设置的过大，则在提交的任务数量太多的情况下，并发量会增加，那么线程之间的调度就是一个要考虑的问题，因为这样反而有可能降低处理任务的吞吐量。 ThreadFactory threadFactory 它是 ThreadFactory 类型的变量，用来创建新线程。默认使用 Executors.defaultThreadFactory() 来创建线程。使用默认的 ThreadFactory 来创建线程时，会使新创建的线程具有相同的 NORM_PRIORITY 优先级并且是非守护线程，同时也设置了线程的名称。 RejectedExecutionHandler handler 它是 RejectedExecutionHandler 类型的变量，表示线程池的饱和策略。如果阻塞队列满了并且没有空闲的线程，这时如果继续提交任务，就需要采取一种策略处理该任务。线程池提供了 4 种策略(拒绝策略)： AbortPolicy 直接抛出异常，这是默认策略； CallerRunsPolicy 用调用者所在的线程来执行任务； DiscardOldestPolicy 丢弃阻塞队列中靠最前的任务，并执行当前任务； DiscardPolicy 直接丢弃任务； 其他几个构造器分别依赖这个构造器，我们只需看这个构造器就可以了 123456789101112131415161718192021public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler;&#125; 这段代码的逻辑： 判断核心线程数： 如果运行的线程少于 corePoolSize，则创建新线程来处理任务，即使线程池中的其他线程是空闲的； 如果线程池中的线程数量大于等于 corePoolSize 且小于 maximumPoolSize，则只有当 workQueue 满时才创建新的线程去处理任务； 如果设置的 corePoolSize 和 maximumPoolSize 相同，则创建的线程池的大小是固定的，这时如果有新任务提交，若 workQueue 未满，则将请求放入 workQueue 中，等待有空闲的线程去从 workQueue 中取任务并处理； 如果运行的线程数量大于等于 maximumPoolSize，这时如果 workQueue 已经满了，则通过 handler 所指定的策略来处理任务； 判断任务队列对象或者线程工厂对象或者拒绝处理对象是否为空 赋值 springboot 中线程池配置与使用springboot 中通常是使用@Configuration 配置线程池，然后使用@Bean 注解将线程池添加到 spring 容器中 12345678@Configurationpublic class ThreadPoolConfig&#123; @Bean public ExecutorService getThreadPool()&#123; return newFixedThreadPool(5); &#125;&#125; 对于线程池的使用，只需通过指定名称进行加载 123456789@Autowiredprivate ExecutorService downloadQueueThreadPool;public void todo()&#123; executorService.execute(()-&gt;&#123; System.out.println(&quot;线程池打印&quot;); // 此处内部类引入外部变量需要为泪下按量或者使用final修饰的变量，所以若需要迭代输出，可通过内部类的方式进行输出 &#125;);&#125; 此处有另外的引入方式,即通过注解@Autowired&lt;!–// 在config中配置 @Bean(name = “downloadQueueThreadPool”)@resource(name=”downloadQueueThreadPool”)private ExecutorService downloadQueueThreadPool; 注解@Autowired 与@resource 的区别是一个是 spring 提供，另一个是 Java 规范，作用类似，@Autowired注释进行byType注入。@Resource的作用相当于@Autowired，只不过@Autowired按byType自动注入，而@Resource默认按 byName自动注入罢了 @Resource有两个属性是比较重要的，分是name和type，Spring将@Resource注解的name属性解析为bean的名字，而type属性则解析为bean的类型。所以如果使用name属性，则使用byName的自动注入策略，而使用type属性时则使用byType自动注入策略。如果既不指定name也不指定type属性，这时将通过反射机制使用byName自动注入策略。 –&gt;@Configuration 的作用 @Bean 的作用 同步与异步 所谓异步则是：你在餐厅带你了一份饭，然后告诉他们你去外面做其他事情去了,让他们饭做好了叫你(回调)而同步得分执行则是：你一直呆在餐厅中等待饭做好才去吃饭，中间时间段内并不能去做其他的事情 这儿就需要使用注解 @Async 与@EnableAsync demo 示例 建立 springboot 项目 这儿我们我们选择依赖 Rest Repositories 点击完成便构建了一个 Springboot 项目。 Rest Repositories 依赖的作用 新建一个 DemoController 类 新建立一个 DemoController 1234567891011@RestController@RequestMapping(&quot;/demo&quot;)public class DemoController &#123; @GetMapping public Map&lt;String,Object&gt; sayHello()&#123; Map&lt;String,Object&gt; map = new HashMap&lt;&gt;(); map.put(&quot;message&quot;,&quot;Hello world&quot;); return map; &#125;&#125; 配置线程池 在 config 包下建立 ThreadPoolConfig 配置我们需要的线程池 12345678@Configurationpublic class ThreadPoolConfig &#123; @Bean public ExecutorService getThreadPool() &#123; return Executors.newFixedThreadPool(5); &#125;&#125; 使用线程池 这里我们有可以看看同步、异步、线程池的效果 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253@Servicepublic class CookService &#123; @Autowired private ExecutorService executorService;// @Bean(name= &quot;downloadQueueThreadPool&quot;)// @Resource(name = &quot;downloadQueueThreadPool&quot;)// private ExecutorService downloadQueueThreadPool; public String cookOneFood() &#123; return &quot;同步完成： &quot; + cook(); &#125; @Async public String cookAsyncFood() &#123; return &quot;异步完成： &quot; + cook(); &#125; public List&lt;String&gt; cookMultiFood(int count) &#123; final List&lt;Future&gt; futureList = new ArrayList&lt;&gt;(); final List&lt;String&gt; resultList = new ArrayList&lt;&gt;(); for(int i = 0; i &lt; count; i++) &#123; futureList.add( executorService.submit(()-&gt;&#123; return cook(); &#125;) ); &#125; for(Future future: futureList) &#123; try &#123; resultList.add(&quot;多线程完成： &quot; + future.get()); &#125; catch (InterruptedException | ExecutionException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; return resultList; &#125; private String cook() &#123; try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; return &quot;一份煮饭&quot;; &#125;&#125; 然后修改相应的 controller","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://duiliuliu.github.io/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://duiliuliu.github.io/tags/SpringBoot/"}]},{"title":"jest与enzyme对react项目自动化测试","slug":"2018-07-07-jest与enzyme对react项目自动化测试","date":"2018-07-06T16:00:00.000Z","updated":"2019-03-02T11:23:56.729Z","comments":true,"path":"2018/07/07/2018-07-07-jest与enzyme对react项目自动化测试/","link":"","permalink":"http://duiliuliu.github.io/2018/07/07/2018-07-07-jest与enzyme对react项目自动化测试/","excerpt":"","text":"jest与enzyme对react项目自动化测试 基于jest和enzyme的特性，我们对一个react项目，可以进行以下几类测试。 组件UI测试snapshot可以测试到组件的渲染结果是否符合预期，预期就是指你上一次录入保存的结果，toMatchSnapshot方法会去帮你对比这次将要生成的结构与上次的区别 12345678910111213it(&apos;use arrowPointAtCenter&apos;, () =&gt; &#123; const wrapper = render( &lt;div&gt; &lt;Tooltip placement=&quot;topLeft&quot; title=&quot;Prompt Text&quot;&gt; &lt;Button&gt;Align edge / 边缘对齐&lt;/Button&gt; &lt;/Tooltip&gt; &lt;Tooltip placement=&quot;topLeft&quot; title=&quot;Prompt Text&quot; arrowPointAtCenter&gt; &lt;Button&gt;Arrow points to center / 箭头指向中心&lt;/Button&gt; &lt;/Tooltip&gt; &lt;/div&gt; ); expect(toJson(wrapper)).toMatchSnapshot();&#125;) dom交互测试: jest+enzymeenzyme有3种渲染方式：render、mount、shallow render采用的是第三方库Cheerio的渲染，渲染结果是普通的html结构，对于snapshot使用render比较合适。 shallow和mount对组件的渲染结果不是html的dom树，而是react树，如果你chrome装了react devtool插件，他的渲染结果就是react devtool tab下查看的组件结构，而render函数的结果是element tab下查看的结果。 这些只是渲染结果上的差别，更大的差别是shallow和mount的结果是个被封装的ReactWrapper，可以进行多种操作，譬如find()、parents()、children()等选择器进行元素查找；state()、props()进行数据查找，setState()、setprops()操作数据；simulate()模拟事件触发。 shallow只渲染当前组件，只能能对当前组件做断言；mount会渲染当前组件以及所有子组件，对所有子组件也可以做上述操作。一般交互测试都会关心到子组件，我使用的都是mount。但是mount耗时更长，内存啥的也都占用的更多，如果没必要操作和断言子组件，可以使用shallow。 api .find(selector): 查找当前包装器的呈现树中与提供的选择器匹配的每个节点。.get(index)：返回指定位置的子组件的DOM节点.at(index)：返回指定位置的子组件.first()：返回第一个子组件.last()：返回最后一个子组件.type()：返回当前组件的类型.text()：返回当前组件的文本内容.html()：返回当前组件的HTML代码形式.props()：返回根组件的所有属性.prop(key)：返回根组件的指定属性.state([key])：返回根组件的状态.setState(nextState)：设置根组件的状态.setProps(nextProps)：设置根组件的属性 shallowshallow方法就是官方的shallow rendering的封装。 Shallow renders the current node and returns a shallow wrapper around it. NOTE: can only be called on wrapper of a single node. 1234567891011121314151617181920function Bar() &#123; return ( &lt;div&gt; &lt;div className=&quot;in-bar&quot; /&gt; &lt;/div&gt; );&#125;function Foo() &#123; return ( &lt;div&gt; &lt;Bar /&gt; &lt;/div&gt; );&#125;const wrapper = shallow(&lt;Foo /&gt;);expect(wrapper.find(&apos;.in-bar&apos;)).to.have.length(0);expect(wrapper.find(Bar)).to.have.length(1);expect(wrapper.find(Bar).shallow().find(&apos;.in-bar&apos;)).to.have.length(1); renderrender方法将React组件渲染成静态的HTML字符串，然后分析这段HTML代码的结构，返回一个对象。它跟shallow方法非常像，主要的不同是采用了第三方HTML解析库Cheerio，它返回的是一个Cheerio实例对象。 12345678import &#123;render&#125; from &apos;enzyme&apos;;describe(&apos;Enzyme Render&apos;, function () &#123; it(&apos;Todo item should not have todo-done class&apos;, function () &#123; let app = render(&lt;App/&gt;); expect(app.find(&apos;.todo-done&apos;).length).to.equal(0); &#125;);&#125;); mount A method that re-mounts the component. This can be used to simulate a component going through an unmount/mount lifecycle. mount方法用于将react组件加载为真实的dom节点。 语法: function mount(node, options) { return new _ReactWrapper2‘default’;} 12345678910import &#123;mount&#125; from &apos;enzyme&apos;;describe(&apos;Enzyme Mount&apos;, function () &#123; it(&apos;Delete Todo&apos;, function () &#123; let app = mount(&lt;App/&gt;); let todoLength = app.find(&apos;li&apos;).length; app.find(&apos;button.delete&apos;).at(0).simulate(&apos;click&apos;); expect(app.find(&apos;li&apos;).length).to.equal(todoLength - 1); &#125;);&#125;); 上面代码中，find方法返回一个对象，包含了所有符合条件的子组件。在它的基础上，at方法返回指定位置的子组件，simulate方法就在这个组件上触发某种行为。 对于交互事件的测试使用simulate进行模拟事件 12345678910111213141516171819202122232425class Foo extends React.Component &#123; constructor(props) &#123; super(props); this.state = &#123; count: 0 &#125;; &#125; render() &#123; const &#123; count &#125; = this.state; return ( &lt;div&gt; &lt;div className=&#123;`clicks-$&#123;count&#125;`&#125;&gt; &#123;count&#125; clicks &lt;/div&gt; &lt;a href=&quot;url&quot; onClick=&#123;() =&gt; &#123; this.setState(&#123; count: count + 1 &#125;); &#125;&#125;&gt; Increment &lt;/a&gt; &lt;/div&gt; ); &#125;&#125;const wrapper = mount(&lt;Foo /&gt;);expect(wrapper.find(&apos;.clicks-0&apos;).length).to.equal(1);wrapper.find(&apos;a&apos;).simulate(&apos;click&apos;);expect(wrapper.find(&apos;.clicks-1&apos;).length).to.equal(1); 也可以对相应的组件属性的事件显示触发 1234567891011121314151617it(&quot;named &apos;SnackBar&apos; exists&quot;, () =&gt; &#123; const event = &#123; keyCode: 1 &#125;; enzymeWrapper .find(&quot;Button[label=&apos;DOWNLOAD&apos;]&quot;) .props() .onClick(event); enzymeWrapper .find(&quot;ConfirmDialog&quot;) .props() .onClickConfirm(); enzymeWrapper .find(&quot;Snackbar&quot;) .props() .onRequestClose(); &#125;); 上述代码测试了点击download按钮后会弹出一个dialog，其中有确定按钮(onClickConfirm)与取消按钮(onClickCancel),点击确定后，文件download之后会有message的反馈。","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://duiliuliu.github.io/categories/JavaScript/"},{"name":"测试","slug":"JavaScript/测试","permalink":"http://duiliuliu.github.io/categories/JavaScript/测试/"}],"tags":[{"name":"测试","slug":"测试","permalink":"http://duiliuliu.github.io/tags/测试/"},{"name":"jest","slug":"jest","permalink":"http://duiliuliu.github.io/tags/jest/"},{"name":"React","slug":"React","permalink":"http://duiliuliu.github.io/tags/React/"},{"name":"enzyme","slug":"enzyme","permalink":"http://duiliuliu.github.io/tags/enzyme/"}]},{"title":"自动化测试jest","slug":"2018-06-31-自动化测试jest","date":"2018-06-30T16:00:00.000Z","updated":"2019-03-02T11:28:49.479Z","comments":true,"path":"2018/07/01/2018-06-31-自动化测试jest/","link":"","permalink":"http://duiliuliu.github.io/2018/07/01/2018-06-31-自动化测试jest/","excerpt":"react单元测试框架Jest入门示例","text":"react单元测试框架Jest入门示例 ##前段测试框架jest mathers 匹配器 相等toBe(value)： 比较数字、字符串toEqual(value)： 比较对象、数组toBeNull() 仅当expect返回对象为 null时toBeUndefined() 仅当返回为 undefinedtoBeDefined 和上面的刚好相反，对象如果有定义时 123456789101112131415it(&quot;should 3 plus 3 is 6&quot;, =&gt; &#123; expect(3+3).toBe(6);&#125;)test(&apos;two plus two&apos;, () =&gt; &#123; const value = 2 + 2; expect(value).toBeGreaterThan(3); expect(value).toBeGreaterThanOrEqual(3.5); expect(value).toBeLessThan(5); expect(value).toBeLessThanOrEqual(4.5); // toBe and toEqual are equivalent for numbers expect(value).toBe(4); expect(value).toEqual(4);&#125;); 需要注意的是对于float类型的浮点数计算的时候，需要使用toBeCloseTo而不是 toEqual ，因为避免细微的四舍五入引起额外的问题 12345test(&apos;adding floating point numbers&apos;, () =&gt; &#123; const value = 0.1 + 0.2; //expect(value).toBe(0.3); This won&apos;t work because of rounding error expect(value).toBeCloseTo(0.3); // This works.&#125;); 12345678test(&apos;null&apos;, () =&gt; &#123; const n = null; expect(n).toBeNull(); expect(n).toBeDefined(); expect(n).not.toBeUndefined(); expect(n).not.toBeTruthy(); expect(n).toBeFalsy();&#125;); 包含toHaveProperty(keyPath, value)： 是否有对应的属性toContain(item)： 是否包含对应的值，括号里写上数组、字符串toMatch(regexpOrString)： 括号里写上正则 1234567891011const shoppingList = [ &apos;diapers&apos;, &apos;kleenex&apos;, &apos;trash bags&apos;, &apos;paper towels&apos;, &apos;beer&apos;,];test(&apos;the shopping list has beer on it&apos;, () =&gt; &#123; expect(shoppingList).toContain(&apos;beer&apos;);&#125;); 逻辑toBeTruthy()toBeFalsy()在JavaScript中，有六个falsy值：false，0，’’，null， undefined，和NaN。其他一切都是Truthy。 toBeGreaterThan(number)： 大于toBeLessThan(number)： 小于 取反 not 1234567test(&apos;adding positive numbers is not zero&apos;, () =&gt; &#123; for (let a = 1; a &lt; 10; a++) &#123; for (let b = 1; b &lt; 10; b++) &#123; expect(a + b).not.toBe(0); &#125; &#125;&#125;); 字符型匹配使用toMatch匹配规则，支持正则表达式匹配 1234567test(&apos;there is no I in team&apos;, () =&gt; &#123; expect(&apos;team&apos;).not.toMatch(/I/);&#125;);test(&apos;but there is a &quot;stop&quot; in Christoph&apos;, () =&gt; &#123; expect(&apos;Christoph&apos;).toMatch(/stop/);&#125;); 异常匹配可以用toThrow测试function是否会抛出特定的异常信息 123456789101112function compileAndroidCode() &#123; throw new ConfigError(&apos;you are using the wrong JDK&apos;);&#125;test(&apos;compiling android goes as expected&apos;, () =&gt; &#123; expect(compileAndroidCode).toThrow(); expect(compileAndroidCode).toThrow(ConfigError); // You can also use the exact error message or a regexp expect(compileAndroidCode).toThrow(&apos;you are using the wrong JDK&apos;); expect(compileAndroidCode).toThrow(/JDK/);&#125;); 其他.toBeCalledWith().toHaveBeenCalledWith() 使用.toHaveBeenCalledWith以确保模拟函数被调用的具体参数。 1234567test(&apos;registration applies correctly to orange La Croix&apos;, () =&gt; &#123; const beverage = new LaCroix(&apos;orange&apos;); register(beverage); const f = jest.fn(); applyToAll(f); expect(f).toHaveBeenCalledWith(beverage);&#125;); .toBeCalledTimes(number).toHaveBeenCalledTimes(number).toBeCalled().toHaveBeenCalled().toHaveReturned() 如果你有一个模拟函数，你可以.toHaveReturned用来测试模拟函数成功返回（即，没有抛出错误）至少一次。 1234567test(&apos;drinks returns&apos;, () =&gt; &#123; const drink = jest.fn(() =&gt; true); drink(); expect(drink).toHaveReturned();&#125;); .toHaveReturnedWith(value) 使用.toHaveReturnedWith以确保模拟函数返回的特定值。 12345678test(&apos;drink returns La Croix&apos;, () =&gt; &#123; const beverage = &#123;name: &apos;La Croix&apos;&#125;; const drink = jest.fn(beverage =&gt; beverage.name); drink(beverage); expect(drink).toHaveReturnedWith(&apos;La Croix&apos;);&#125;); 测试函数 同步函数 12345678\\\\s.jsconst sum = (a,b) =&gt; a + b;\\\\_test_/s.test.jsimport * as s from &apos;../s&apos;test(&quot;should sum(2,2) is 4&quot;,()=&gt;&#123; except(s.sum(2,2)).toBe(4);&#125;) 异步函数对于异步函数，比如 ajax 请求，测试写法同样容易 待测试文件：client.js 1234567891011121314151617181920212223\\\\client.jsexport const get = (url, headers = &#123;&#125;) =&gt; &#123; return fetch(url, &#123; method: &apos;GET&apos;, headers: &#123; ...getHeaders(), ...headers &#125; &#125;).then(parseResponse)&#125;\\\\_test_/client.test.jsimport * as client from &apos;../s&apos;test(&apos;fetch by get method&apos;, async () =&gt; &#123; expect.assertions(1) // 测试使用了一个免费的在线 JSON API const url = &apos;https://jsonip.com/&apos; const data = await get(url) const &#123; about &#125; = data expect(about).toBe(&apos;/about&apos;)&#125;) 测试的生命周期 afterAll(fn, timeout): 当前文件中的所有测试执行完成后执行 fn, 如果 fn 是 promise，jest 会等待 timeout 毫秒，默认 5000 afterEach(fn, timeout): 每个 test 执行完后执行 fn，timeout 含义同上 beforeAll(fn, timeout): 同 afterAll，不同之处在于在所有测试开始前执行 beforeEach(fn, timeout): 同 afterEach，不同之处在于在每个测试开始前执行 1234567891011121314151617181920212223BeforeAll(() =&gt; &#123; console.log(&apos;before all tests to excute !&apos;)&#125;)BeforeEach(() =&gt; &#123;c onsole.log(&apos;before each test !&apos;)&#125;)AfterAll(() =&gt; &#123; console.log(&apos;after all tests to excute !&apos;)&#125;)AfterEach(() =&gt; &#123; console.log(&apos;after each test !&apos;)&#125;)Test(&apos;test lifecycle 01&apos;, () =&gt; &#123; expect(1 + 2).toBe(3)&#125;)Test(&apos;test lifecycle 03&apos;, () =&gt; &#123; expect(2 + 2).toBe(4)&#125;)","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://duiliuliu.github.io/categories/JavaScript/"}],"tags":[{"name":"测试","slug":"测试","permalink":"http://duiliuliu.github.io/tags/测试/"},{"name":"jest","slug":"jest","permalink":"http://duiliuliu.github.io/tags/jest/"},{"name":"React","slug":"React","permalink":"http://duiliuliu.github.io/tags/React/"}]},{"title":"javascript-export、import用法","slug":"2018-06-26-javascript-export用法","date":"2018-06-25T16:00:00.000Z","updated":"2019-03-02T11:29:26.951Z","comments":true,"path":"2018/06/26/2018-06-26-javascript-export用法/","link":"","permalink":"http://duiliuliu.github.io/2018/06/26/2018-06-26-javascript-export用法/","excerpt":"export语句用于在创建JavaScript模块时，从模块中导出函数、对象或原始值，以便其他程序可以通过 import 语句使用它们。 import语句用于导入由另一个模块导出的绑定。无论是否声明了 strict mode ，导入的模块都运行在严格模式下。import语句不能在嵌入式脚本中使用。","text":"export语句用于在创建JavaScript模块时，从模块中导出函数、对象或原始值，以便其他程序可以通过 import 语句使用它们。 import语句用于导入由另一个模块导出的绑定。无论是否声明了 strict mode ，导入的模块都运行在严格模式下。import语句不能在嵌入式脚本中使用。 javascript-export、import用法 export语法export语句用于在创建JavaScript模块时，从模块中导出函数、对象或原始值，以便其他程序可以通过 import 语句使用它们。 123456789101112131415export &#123; name1, name2, …, nameN &#125;;export &#123; variable1 as name1, variable2 as name2, …, nameN &#125;;export let name1, name2, …, nameN; // also var (const 定义的是常量，需要在初始化的时候赋值)export let name1 = …, name2 = …, …, nameN; // also var, constexport function FunctionName() &#123;...&#125;export class ClassName &#123;...&#125;export default expression;export default function (…) &#123; … &#125; // also class, function*export default function name1(…) &#123; … &#125; // also class, function*export &#123; name1 as default, … &#125;;export * from …;export &#123; name1, name2, …, nameN &#125; from …;export &#123; import1 as name1, import2 as name2, …, nameN &#125; from …; 有两种不同的导出方式，每种方式对应于上述的一种语法： 命名导出： 12345// exports a function declared earlierexport &#123; myFunction &#125;;// exports a constantexport const foo = Math.sqrt(2); 默认导出（函数）： 1export default function() &#123;&#125; 默认导出（类）： 1export default class &#123;&#125; 命名导出对导出多个值很有用。在导入期间，必须使用相应对象的相同名称。 对于默认导出，可以以任何名称导入，并且导入时不需要{} 12345export default k = 12; // in file test.jsimport m from &apos;./test&apos; // note that we got the freedom to use import m instead of import k, because k was default exportconsole.log(m); // will log 12 export示例 使用命名导出在模块中，我们可以使用以下代码： 123456// module &quot;my-module.js&quot;function cube(x) &#123;return x * x * x;&#125;const foo = Math.PI + Math.SQRT2;export &#123; cube,foo &#125;; 这样的话，在其它脚本 (比如import)，我们可以这样使用： 123import &#123; cube, foo &#125; from &apos;my-module.js&apos;;console.log(cube(3)); // 27console.log(foo); // 4.555806215962888 使用默认导出如果我们要导出一个值或模块中的返回值，就可以使用默认导出： // module “my-module.js”export default function cube(x) {return x x x;}然后，在另一个脚本中，可以直接导入默认导出： // module “my-module.js”import cube from ‘my-module’;console.log(cube(3)); // 27​​​​​注意，不能使用var，let或const作为默认导出。 import语法import语句用于导入由另一个模块导出的绑定。无论是否声明了 strict mode ，导入的模块都运行在严格模式下。import语句不能在嵌入式脚本中使用。 现在浏览器们才刚刚开始去实现这个功能。但它在许多转换器中已经实现，例如 Traceur Compiler ， Babel ， Rollup 或 Webpack。 123456789import defaultExport from &quot;module-name&quot;;import * as name from &quot;module-name&quot;;import &#123; export &#125; from &quot;module-name&quot;;import &#123; export as alias &#125; from &quot;module-name&quot;;import &#123; export1 , export2 &#125; from &quot;module-name&quot;;import &#123; export1 , export2 as alias2 , [...] &#125; from &quot;module-name&quot;;import defaultExport, &#123; export [ , [...] ] &#125; from &quot;module-name&quot;;import defaultExport, * as name from &quot;module-name&quot;;import &quot;module-name&quot;; defaultExport将引用模块默认导出的名称。 module-name要导入的模块。这通常是包含模块的.js文件的相对或绝对路径名，不包括.js扩展名。某些打包工具可以允许或要求使用该扩展；检查你的运行环境。只允许单引号和双引号的字符串。 name引用时将用作一种命名空间的模块对象的名称。 export, exportN要导入的导出名称。 alias, aliasN将引用指定的导入的名称。 name参数是“模块对象”的名称，它将用一种名称空间来引用导出。导出参数指定单个命名导出，而import * as name语法导入所有导出。以下示例阐明该语法。 导入整个模块的内容这将myModule插入当前作用域，其中包含来自位于/modules/my-module.js文件中导出的所有模块。 1import * as myModule from &apos;/modules/my-module.js&apos;; 在这里，访问导出意味着使用模块名称（在这种情况下为“myModule”）作为命名空间。例如，如果上面导入的模块包含一个doAllTheAmazingThings()，你可以这样调用： 1myModule.doAllTheAmazingThings(); 导入单个导出给定一个名为myExport的对象或值，它已经从模块my-module导出（因为整个模块被导出）或显式地导出（使用export语句），将myExport插入当前作用域。 1import &#123;myExport&#125; from &apos;/modules/my-module.js&apos;; 导入多个导出这将foo和bar插入当前作用域。 1import &#123;foo, bar&#125; from &apos;/modules/my-module.js&apos;; 导入带有别名的导出导入时可以重命名导出。例如，将shortName插入当前作用域。 12import &#123;reallyReallyLongModuleExportName as shortName&#125; from &apos;/modules/my-module.js&apos;; 导入时重命名多个导出使用别名导入模块的多个导出。 1234import &#123; reallyReallyLongModuleMemberName as shortName, anotherLongModuleName as short&#125; from &quot;my-module&quot;; 仅为副作用而导入一个模块模块仅为副作用（中性词，无贬义含义）而导入，而不导入模块中的任何内容。 这将运行模块中的全局代码, 但实际上不导入任何值。 1import &apos;/modules/my-module.js&apos;; 导入默认值在defaultexport（无论是对象，函数，类等）有效时可用。然后可以使用import语句来导入这样的默认值。 最简单的用法是直接导入默认值： 1import myDefault from &quot;my-module&quot;; 也可以同时将default语法与上述用法（命名空间导入或命名导入）一起使用。在这种情况下，default导入必须首先声明。 例如： 123456import myDefault, * as myModule from &quot;my-module&quot;;// myModule used as a namespace//或者import myDefault, &#123;foo, bar&#125; from &quot;my-module&quot;;// specific, named imports import示例从辅助模块导入以协助处理AJAX JSON请求。 模块：file.js123456789101112function getJSON(url, callback) &#123; let xhr = new XMLHttpRequest(); xhr.onload = function () &#123; callback(this.responseText) &#125;; xhr.open(&apos;GET&apos;, url, true); xhr.send();&#125;export function getUsefulContents(url, callback) &#123; getJSON(url, data =&gt; callback(JSON.parse(data)));&#125; 主程序：main.js1234import &#123; getUsefulContents &#125; from &apos;/modules/file.js&apos;;getUsefulContents(&apos;http://www.example.com&apos;, data =&gt; &#123; doSomethingUseful(data); &#125;);","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://duiliuliu.github.io/categories/JavaScript/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://duiliuliu.github.io/tags/JavaScript/"}]},{"title":"Ubantu 搭建FTP文件服务","slug":"2018-06-12-Ubantu 搭建FTP文件服务","date":"2018-06-11T16:00:00.000Z","updated":"2019-03-02T11:29:21.221Z","comments":true,"path":"2018/06/12/2018-06-12-Ubantu 搭建FTP文件服务/","link":"","permalink":"http://duiliuliu.github.io/2018/06/12/2018-06-12-Ubantu 搭建FTP文件服务/","excerpt":"","text":"Ubantu 搭建FTP文件服务 安装并启动FTP服务 安装VSFTPD 使用apt-get安装1sudo apt-get install vsftpd -y 启动VSFTPD安装完成后 VSFTPD 会自动启动，通过 netstat 命令可以看到系统已经监听了 21 端口 12sudo netstat -nltp | grep 21grep 21 匹配21端口 如果没有启动，可以手动VSFTPD服务1sudo systemctl start vsftpd.service 配置用户访问目录 新建用户主目录 1sudo mkdir /home/uftp 执行完后，在这里 /home/uftp将是我们开放访问的目录创建登录欢迎文件 1sudo touch /home/uftp/welcome.txt 新建用户uftp并设置密码创建一个用户uftp 1sudo useradd -d /home/uftp -s /bin/bash uftp 为用户uftp设置密码 1sudo passwd uftp 删除掉pam.d中的vsftpd，因为该配置文件会导致使用用户名登录ftp失败 1sudo rm /etc/pam.d/vsftpd 限制该用户仅能通过ftp访问限制用户 uftp 只能通过 FTP 访问服务器，而不能直接登录服务器： 1sudo usermod -s /sbin/nologin uftp 修改vsftpd配置 1sudo chmod a+w /etc/vsftpd.conf 修改 /etc/vsftpd.conf 文件中的配置（直接将如下配置添加到配置文件最下方）： 123456789101112131415161718# 限制用户对主目录以外目录访问chroot_local_user=YES-# 指定一个 userlist 存放允许访问 ftp 的用户列表userlist_deny=NOuserlist_enable=YES-# 记录允许访问 ftp 用户列表userlist_file=/etc/vsftpd.user_list-# 不配置可能导致莫名的530问题seccomp_sandbox=NO-# 允许文件上传write_enable=YES-# 使用utf8编码utf8_filesystem=YES 新建文件 /etc/vsftpd.user_list，用于存放允许访问 ftp 的用户： 12 sudo touch /etc/vsftpd.user_listsudo chmod a+w /etc/vsftpd.user_list 修改 /etc/vsftpd.user_list ，加入刚刚创建的用户： 1uftp 设置访问权限设置主目录访问权限（只读）： 1sudo chmod a-w /home/uftp 新建公共目录，并设置权限（读写）： 1sudo mkdir /home/uftp/public &amp;&amp; sudo chmod 777 -R /home/uftp/public 重启vsftpd 服务： 1sudo systemctl restart vsftpd.service 准备域名和证书注：如果不需要通过域名访问 FTP 服务器,可跳过 将购买的域名解析到IP上ping www.yourdomain.com如果 ping 命令返回的信息中含有你设置的解析的 IP 地址，说明解析成功。 访问 FTP 服务 访问 FTP 服务 FTP 客户端工具众多，下面推荐两个常用的： FileZilla - 跨平台的 FTP 客户端，支持 Windows 和 Mac WinSCP - Windows 下的 FTP 和 SFTP 连接客户端下载和安装 FTP 客户端后，使用下面的凭据进行连接即可： 主机 :119.29.174.183用户：uftp 输入密码后，如果能够正常连接，那么大功告成，您可以开始使用属于您自己的 FTP 服务器了！接下来，请上传任意一张图片到您的 FTP 服务器上的 uftp 的 public 目录下，然后，就可以在 /home/uftp/public 中看到了。 通过 Windows 资源管理器访问Windows 用户可以复制下面的链接到资源管理器的地址栏访问：ftp://uftp:你的密码@119.29.174.183","categories":[{"name":"Linux","slug":"Linux","permalink":"http://duiliuliu.github.io/categories/Linux/"}],"tags":[{"name":"Linux ftp","slug":"Linux-ftp","permalink":"http://duiliuliu.github.io/tags/Linux-ftp/"}]},{"title":"js中forEach与map","slug":"2018-06-01-js中forEach与map","date":"2018-05-31T16:00:00.000Z","updated":"2019-03-02T11:29:16.798Z","comments":true,"path":"2018/06/01/2018-06-01-js中forEach与map/","link":"","permalink":"http://duiliuliu.github.io/2018/06/01/2018-06-01-js中forEach与map/","excerpt":"javasc中，map与foreach都可用作遍历，有较多得相同点，本文用以记录二者异同","text":"javasc中，map与foreach都可用作遍历，有较多得相同点，本文用以记录二者异同 js中forEach与map 共同点： 1、都是循环遍历数组中的每一项。 2、forEach()和map()里面每一次执行匿名函数都支持3个参数：数组中的当前项item,当前项的索引index,原始数组input。 3、匿名函数中的this都是指Window。 区别： foreach 无返回值，而map有返回值 forEach和map还存在一个编程思想的区别，前者是命令式编程，后者是声明式编程，如果项目的风格是声明式的，比如React，那么后者显然更统一。 forEach 语法 12345678910111213array.forEach(callback(currentValue, index, array)&#123; //do something&#125;, this)//或者array.forEach(callback(currentValue, index, array)&#123; //do something&#125;) //或者 lambda表达式，较简便array.forEach(element =&gt; &#123; &#125;); callback 函数会被依次传入三个参数： 数组当前项的值 数组当前项的索引 数组对象本身 如果给forEach传递了thisArg参数，当调用时，它将被传给callback 函数，作为它的this值。否则，将会传入 undefined 作为它的this值。 因为js中的数组时引用类型，所以可以用foreach来更新数组 注意 在使用forEach()时候，如果数组在迭代的视乎被修改，则其他元素会被跳过。因为 forEach()不会在迭代之前创建数组的副本。 12345678910var words = [&quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;];words.forEach(word =&gt; &#123; console.log(word); if (word === &quot;2&quot;)&#123; words.shift(); &#125;&#125;);// 1// 2// 4 map 语法 12345678910var new_array = arr.map(callback[, thisArg]) //或者 有返回值arr[].map(function(value,index,array)&#123; //do something return XXX&#125;) 参数：value数组中的当前项,index当前项的索引,array原始数组； 如： 123456var ary = [12,23,24,42,1]; var res = ary.map(function (item,index,input) &#123; return item*10; &#125;) console.log(res);//--&gt;[120,230,240,420,10]; 原数组拷贝了一份，并进行了修改console.log(ary);//--&gt;[12,23,24,42,1]； 原数组并未发生变化 如：反转字符串： 1234var str = &apos;12345&apos;;Array.prototype.map.call(str, function(x) &#123; //同时利用了call()方法return x;&#125;).reverse().join(&apos;&apos;); 注意 1[&quot;1&quot;, &quot;2&quot;, &quot;3&quot;].map(parseInt); //结果 [1, NaN, NaN] 如果想得到[1, 2,3]应该这么做 12345function returnInt(element)&#123;return parseInt(element,10);&#125; [&quot;1&quot;, &quot;2&quot;, &quot;3&quot;].map(returnInt); 这主要是因为 parseInt()默认有两个参数，第二个参数是进制数。当parsrInt没有传入参数的时候，而map()中的回调函数时候，会给它传三个参数，第二个参数就是索引，明显不正确，所以返回NaN了。 兼容写法不管是forEach还是map在IE6-8下都不兼容（不兼容的情况下在Array.prototype上没有这两个方法）,那么需要我们自己封装一个都兼容的方法，代码如下： 12345678910111213141516171819202122232425262728293031323334353637/** * forEach遍历数组 * @param callback [function] 回调函数； * @param context [object] 上下文； */ Array.prototype.myForEach = function myForEach(callback,context)&#123; context = context || window; if(&apos;forEach&apos; in Array.prototye) &#123; this.forEach(callback,context); return; &#125; //IE6-8下自己编写回调函数执行的逻辑 for(var i = 0,len = this.length; i &lt; len;i++) &#123; callback &amp;&amp; callback.call(context,this[i],i,this); &#125; &#125; /** * map遍历数组 * @param callback [function] 回调函数； * @param context [object] 上下文； */ Array.prototype.myMap = function myMap(callback,context)&#123; context = context || window; if(&apos;map&apos; in Array.prototye) &#123; return this.map(callback,context); &#125; //IE6-8下自己编写回调函数执行的逻辑 var newAry = []; for(var i = 0,len = this.length; i &lt; len;i++) &#123; if(typeof callback === &apos;function&apos;) &#123; var val = callback.call(context,this[i],i,this); newAry[newAry.length] = val; &#125; &#125; return newAry; &#125;","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://duiliuliu.github.io/categories/JavaScript/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://duiliuliu.github.io/tags/javascript/"}]},{"title":"git操作详解","slug":"git操作详解","date":"2018-05-20T16:00:00.000Z","updated":"2019-03-02T11:55:01.812Z","comments":true,"path":"2018/05/21/git操作详解/","link":"","permalink":"http://duiliuliu.github.io/2018/05/21/git操作详解/","excerpt":"我们应该每天都在用 git，常用的命令也就那几个：","text":"我们应该每天都在用 git，常用的命令也就那几个： 我们应该每天都在用 git，常用的命令也就那几个： 初始化 git init让我们创建一个项目目录，然后进入该目录 $ mkdir git-demo-project $ cd git-demo-project 接着 git init 初始化 git 仓库 $ git init 以下命令作用差不多： # 在当前目录新建一个Git代码库 $ git init # 新建一个目录，将其初始化为Git代码库 $ git init [project-name] # 下载一个项目和它的整个代码历史 $ git clone [url] git init 主要做的事，那就是在项目的根目录下创建.git 子目录来保存版本信息 $ ls .git branches/ config description HEAD hooks/ info/ objects/ refs/ 上述命令显示了.git 子目录中的内容 配置Git的设置文件为.gitconfig，它可以在用户主目录下（全局配置），也可以在项目目录下（项目配置） 配置主要是用来存储用户信息 显示当前的Git配置 $ git config --list # 编辑Git配置文件 $ git config -e [--global] # 设置提交代码时的用户信息 $ git config [--global] user.name &quot;[name]&quot; $ git config [--global] user.email &quot;[email address]&quot; 保存对象创建好 git 本地仓库后，我们可以写文件然后进行保存 $ touch README.md $ echo 这是我的git练习仓库 &gt; README.md Git 提供了 git add 命令来保存已更改的对象。 $ git add --all 也可以指定单个文件进行保存 $ git add README.md 作用类似的命令 # 添加指定文件到暂存区 $ git add [file1] [file2] ... # 添加指定目录到暂存区，包括子目录 $ git add [dir] # 添加当前目录的所有文件到暂存区 $ git add . # 添加每个变化前，都会要求确认 # 对于同一个文件的多处变化，可以实现分次提交 $ git add -p # 删除工作区文件，并且将这次删除放入暂存区 $ git rm [file1] [file2] ... # 停止追踪指定文件，但该文件会保留在工作区 $ git rm --cached [file] # 改名文件，并且将这个改名放入暂存区 $ git mv [file-original] [file-renamed] 而 git add 命令的实质是由两部分构成的： 保存对象 接下来让我们创建一个新的空文件test.txt。 $ touch test.txt 然后把这个文件添加到Git代码库中，这一步将创建test.txt现有内容的一个副本。 $ git hash-object -w test.txt e69de29bb2d1d6434b8b29ae775ad8c2e48c5391 在上述代码中，git hash-object命令将test.txt现有的内容压缩成二进制文件，并保存到Git中。该压缩文件叫做Git对象，保存在.git/objects目录中。 我们可以通过这个命令根据对象的文件名获取当前内容，并计算成SHA1 哈希（长度为40的字符串）。让我们看看下列新生成的Git对象文件。 $ ls -R .git/objects .git/objects/e6: 9de29bb2d1d6434b8b29ae775ad8c2e48c5391 如上述代码所示，.git/objects目录下又多出了一个子目录，而且这个子目录名是上述哈希值的前两个字符。在这个子目录下有一个文件，文件名是上述哈希值中其余的38个字符。 让我们再来看看文件内容。 $ cat .git/objects/e6/9de29bb2d1d6434b8b29ae775ad8c2e48c5391 上述代码输出的文件内容是一些二进制字符。你可能会问既然test.txt是空文件，又怎么会有这些内容呢？这是因为该二进制对象中还存储了一些元数据。 如果你想看看该文件原始的文本内容，那么应该使用git cat-file。 $ git cat-file -p e69de29bb2d1d6434b8b29ae775ad8c2e48c5391 因为原文件为空，所以上述命令什么都没有显示。现在我们往test.txt文件中写点东西。 $ echo &apos;hello world&apos; &gt; test.txt 这个文件的内容已经改变了，所以你需要再次把它保存为Git对象。 $ git hash-object -w test.txt 3b18e512dba79e4c8300dd08aeb37f8e728b8dad 如上述代码所示，test.txt的哈希值已经随着文件内容的改变而发生了变化。同时还生成了新文件 git/objects/3b/18e512dba79e4c8300dd08aeb37f8e728b8dad。现在你可以看到这个文件的内容了。 $ git cat-file -p 3b18e512dba79e4c8300dd08aeb37f8e728b8dad hello world 更新索引 当文件保存成二进制对象以后，你需要告诉Git哪个文件发生了变化。Git会在一个名叫“索引”（或阶段）的区域记录所有发生了变化的文件。然后等到所有的变更都结束后，将索引中的这些文件一起写入正式的版本历史记录中。 $ git update-index --add --cacheinfo 100644 3b18e512dba79e4c8300dd08aeb37f8e728b8dad test.txt 上述命令记录了文件名test.txt、二进制对象名（哈希值）以及索引中文件的访问权限。 git ls-files命令可以显示索引中当前的内容。 $ git ls-files --stage 100644 3b18e512dba79e4c8300dd08aeb37f8e728b8dad 0 test.txt 上述代码显示索引中只有一个test.txt文件，还显示了该文件的二进制对象名和访问该文件的权限。如果你知道该二进制对象名，就可以查看.git/objects子目录中该文件的内容。 git status命令可以输出更多可读的结果。 $ git status Changes to submit： The new file： test.txt 上述代码显示索引中只有一个新文件test.txt，该文件正在等候写入版本的历史记录中。 git add 命令 针对每个文件执行上述两个步骤非常繁琐。所以Git提供了git add命令来简化这些操作。 $ git add --all 上述命令相当于针对当前项目中所有发生了变化的文件执行上述两个步骤 提交提交的命令： # 提交暂存区到仓库区 $ git commit -m [message] # 提交暂存区的指定文件到仓库区 $ git commit [file1] [file2] ... -m [message] # 提交工作区自上次commit之后的变化，直接到仓库区 $ git commit -a # 提交时显示所有diff信息 $ git commit -v # 使用一次新的commit，替代上一次提交 # 如果代码没有任何新变化，则用来改写上一次commit的提交信息 $ git commit --amend -m [message] # 重做上一次commit，并包括指定文件的新变化 $ git commit --amend [file1] [file2] ... 提交的实质： 提交 索引保存发生了变化的文件信息。等到修改完成，所有这些信息都会被写入版本的历史记录中，这相当于生成一个当前项目的快照。 项目的历史记录由不同时间点的项目快照组成。Git可以将项目恢复成任何一个快照。在Git中“快照”有一个专门的术语，即“提交”（commit）。所以生成快照也可以称之为完成提交。 下列所有“快照”的引用指的都是提交。 完成提交 首先，我们需要设置好用户名和邮件地址。在你保存快照的时候，Git需要记录是谁执行的提交。 $ git config user.name &quot;username&quot; $ git config user.email &quot;Email address&quot; 接下来，保存现有的目录结构。在本文的前面我们讨论了保存对象只会保存一个文件，并不会记录文件之间的目录结构。 git write-tree命令可以根据当前目录结构生成一个Git对象。 $ git write-tree c3b8bb102afeca86037d5b5dd89ceeb0090eae9d 在上述代码中，目录结构保存成了二进制对象，而对象的名字是哈希值。它也保存在.git/objects目录中。 让我们来看看该文件的内容。 $ git cat-file -p c3b8bb102afeca86037d5b5dd89ceeb0090eae9d 100644 blob 3b18e512dba79e4c8300dd08aeb37f8e728b8dad test.txt 可以看到，当前目录中只有一个文件test.txt。 这个所谓的快照就是保存当前的目录结构，以及每个文件相对应的二进制对象。之前的操作已经保存了文件结构，所以现在你需要把这个目录结构和一些元数据一起写入版本的历史记录中。 git commit-tree可以将目录树对象写入到版本的历史记录中。 $ echo &quot;first commit&quot; | git commit-tree c3b8bb102afeca86037d5b5dd89ceeb0090eae9d c9053865e9dff393fd2f7a92a18f9bd7f2caa7fa 在上述代码中，在提交时你需要提供提交的描述，而且你可以通过echo “first commit”提供提交描述。git commit-tree命令会根据元数据以及目录树生成一个Git对象。现在，让我们来看看该对象的内容。 $ git cat-file -p c9053865e9dff393fd2f7a92a18f9bd7f2caa7fa tree c3b8bb102afeca86037d5b5dd89ceeb0090eae9d author jam 1538889134 +0800 committer jam 1538889134 +0800 first commit 在上述代码中，第一行输出是对应于该快照的目录树对象，而第二行和第三行是有关作者和提交者的信息，最后一行内容是提交的描述。 通过git log命令我们还可以查看某个快照的信息。 $ git log --stat c9053865e9dff393fd2f7a92a18f9bd7f2caa7fa commit c9053865e9dff393fd2f7a92a18f9bd7f2caa7fa Author: jam Date: Sun Oct 7 13:12:14 2018 +0800 first commit test.txt | 1 + 1 file changed, 1 insertion(+) git commit 命令 Git提供了git commit来简化上述提交操作。在保存到索引后，你只需要执行git commit命令，就可以同时提交目录结构和描述，并生成快照。 $ git commit -m &quot;first commit&quot; 另外，还有两个命令也非常实用。 通过git checkout命令，我们可以切换到某个快照。 $ git checkout c9053865e9dff393fd2f7a92a18f9bd7f2caa7fa 通过git show命令，我们可以显示某个快照的所有代码变更。 $ git show c9053865e9dff393fd2f7a92a18f9bd7f2caa7fa 分支与分支相关的命令： # 列出所有本地分支 $ git branch # 列出所有远程分支 $ git branch -r # 列出所有本地分支和远程分支 $ git branch -a # 新建一个分支，但依然停留在当前分支 $ git branch [branch-name] # 新建一个分支，并切换到该分支 $ git checkout -b [branch] # 新建一个分支，指向指定commit $ git branch [branch] [commit] # 新建一个分支，与指定的远程分支建立追踪关系 $ git branch --track [branch] [remote-branch] # 切换到指定分支，并更新工作区 $ git checkout [branch-name] # 切换到上一个分支 $ git checkout - # 建立追踪关系，在现有分支与指定的远程分支之间 $ git branch --set-upstream [branch] [remote-branch] # 合并指定分支到当前分支 $ git merge [branch] # 选择一个commit，合并进当前分支 $ git cherry-pick [commit] # 删除分支 $ git branch -d [branch-name] # 删除远程分支 $ git push origin --delete [branch-name] $ git branch -dr [remote/branch] 远程同步相关命令： # 下载远程仓库的所有变动 $ git fetch [remote] # 显示所有远程仓库 $ git remote -v # 显示某个远程仓库的信息 $ git remote show [remote] # 增加一个新的远程仓库，并命名 $ git remote add [shortname] [url] # 取回远程仓库的变化，并与本地分支合并 $ git pull [remote] [branch] # 上传本地指定分支到远程仓库 $ git push [remote] [branch] # 强行推送当前分支到远程仓库，即使有冲突 $ git push [remote] --force # 推送所有分支到远程仓库 $ git push [remote] --all","categories":[{"name":"git","slug":"git","permalink":"http://duiliuliu.github.io/categories/git/"}],"tags":[{"name":"git","slug":"git","permalink":"http://duiliuliu.github.io/tags/git/"}]},{"title":"Chrome开发者工具","slug":"2018-04-23-Chrome开发者工具","date":"2018-04-22T16:00:00.000Z","updated":"2019-03-02T11:29:10.520Z","comments":true,"path":"2018/04/23/2018-04-23-Chrome开发者工具/","link":"","permalink":"http://duiliuliu.github.io/2018/04/23/2018-04-23-Chrome开发者工具/","excerpt":"对于Chrome开发者工具，大家经常使用，但是很少抽时间去完整得看看开发者工具面板得各个功能，以至于使用时会需要去网络上查询","text":"对于Chrome开发者工具，大家经常使用，但是很少抽时间去完整得看看开发者工具面板得各个功能，以至于使用时会需要去网络上查询 Chrome开发者工具对于开发前端的同学与搞爬虫的同学，Chrome开发者工具是不可获取的。熟悉Chrome开发者工具可以更加方便的开发前端或者分析网站。对于开发者工具，可以右键鼠标按钮，然后点击检查；或者使用F12快捷键；或者在设置中找到开发者工具，然后点击。 如图，面板首行有6个按钮 这些按钮的功能点如下： Elements:查找网页源代码HTML中的任一元素,手动修改任一元素的属性和样式且能实时在浏览器里面得到反馈。Console:记录开发者开发过程中的日志信息，且可以作为与JS进行交互的命令行Shell。 Sources:断点调试JS。 Network:从发起网页页面请求Request后分析HTTP请求后得到的各个请求资源信息（包括状态、资源类型、大小、所用时间等），可以根据这个进行网络性能优化。 Timeline:记录并分析在网站的生命周期内所发生的各类事件，以此可以提高网页的运行时间的性能。 Profiles:如果你需要Timeline所能提供的更多信息时，可以尝试一下Profiles,比如记录JS CPU执行时间细节、显示JS对象和相关的DOM节点的内存消耗、记录内存的分配细节。Application:\b记录网站加载的所有资源信息，包括存储数据（Local Storage、Session Storage、IndexedDB、Web SQL、Cookies）、缓存数据、字体、图片、脚本、样式表等。 Security:判断当前网页是否安全。 Audits:对当前网页进行网络利用情况、网页性能方面的诊断，并给出一些优化建议。比如列出所有没有用到的CSS文件等。 Elements面板element面板中可以实时编辑DOM节点和CSS样式，可以更好的调整前端UI。对于某个前端组件，也可快速定位至源码代码处。同样快速定位源代码这个功能可以让搞爬虫的伙伴快速的找到需要的数据节点位置，并利用解析HTML工具进行提取数据。 双击DOM树视图里面的节点，可以实时编辑标签属性，修改的效果会立刻反应在浏览器里面 点击右侧Style面板，可以实时修改CSS的属性值，这里面的所有样式Name和Value都是可以编辑的;在\b每个属性后面单击可以添加新的样式，如下图： 点击右侧Computed面板，可以编辑左侧选中的盒子模型参数，所有的值都是可以修改的;点击不同的位置(top、bottom、left、right) 就可以修改元素的padding、border、margin属性值。 查看网页的本地修改历史 点击Styles面板中修改过属性的文件名，会跳转到Source面板 在文件位置右击选择Local modifications,可以查看本地的所有修改记录 点击指定的时间点可以看到粉红背景的删除内容和绿色背景的添加内容 Console面板控制台可以使用JavaScript语言进行交互操作，对节点的查找支持css选择器、xpath路径查找等。同样可以编写Javascript函数进行操作dom节点。在使用控制台时，换行使用shift+enter。 控制台输出日志 通过JS代码或者命令行console.log()、console.warn()和console.error()可以将\b日志信息输出到控制台 console.log 显示一般的基本日志信息，当要显示的基本日志太多时可以使用console.group将相关的日志进行分组console.warn 显示带有\b黄色小图标的警告信息console.error 显示带有红色小图标的红色的错误信息 注： 当需要换到下一行而不是回车的时候，请按Shift+Enter。 控制台交互 JS表达式计算在上一小节，我们已经看到可以在控制台输入JS表达式点击Enter即可得到表达式的值，当你在控制台输入命令时，会弹出相应的智能提示框，你可以用Tab自动完成当前的建议项 选择元素 $() 返回与指定的CSS选择器相匹配的第一个元素，等同于document.querySelector() $$() 返回与指定的CSS选择器相匹配的所有元素的数组，等同于document.querySelectorAll() $x() 返回与指定的XPath相匹配的所有元素的数组 Sources面板 添加断点 在源代码左边有行号，点击对应行的行号，就好给改行添加上一个断点（再次点击可删除断点）。右键点击断点，在弹出的菜单中选择Edit breakpoint可以给该断的添加中断条件。 中断调试 添加断点后，当JS代码运行到断点时会中断（对于添加了中断条件的断点在符合条件时中断），此时可以将光标放在变量上查看变量的值 也可以在右边的侧栏上查看 在右侧变量上方，有继续运行、单步跳过等按钮，可以在当前断点后，逐行运行代码，或者直接让其继续运行。 network面板network面板是爬虫伙伴常常光顾的，因为network面板可以记录页面上的网络请求的详情信息，从发起网页页面请求Request后分析HTTP请求后得到的各个请求资源信息（包括状态、资源类型、大小、所用时间、Request和Response等）。通过观察网络请求状况，自己动手模拟浏览器请求网络进行获取数据，有的是通过xhr传输json数据的，有的是跨域传输jsonp数据的，也有的是传输xml或html数据。 常用的功能有： ① 查看资源HTTP头信息 在Headers标签里面可以看到HTTP Request URL、HTTP Method、Status Code、Remote Address等基本信息和详细的Response Headers、Request Headers以及Query String Parameters或者Form Data等信息。 ② 查看资源预览信息 在Preview标签里面可根据选择的资源类型（JSON、图片、文本、JS、CSS）显示相应的预览信息。下图显示的是当选择的资源是JSON格式时的预览信息。 ③ 查看资源HTTP的Response信息 在Response标签里面可根据选择的资源类型（JSON、图片、文本、JS、CSS）显示相应资源的Response响应内容。下图显示的是当选择的资源是CSS格式时的响应内容。 ④ 查看资源Cookies信息 如果选择的资源在Request和Response过程中存在Cookies信息，则Cookies标签会自动显示出来，在里面可以查看所有的Cookies信息。 ⑤ 分析资源在请求的生命周期内各部分时间花费信息 在Timing标签中可以显示资源在整个请求生命周期过程中各部分时间花费信息，可能会涉及到如下过程的时间花费情况： Queuing 排队的时间花费。可能由于该请求被渲染引擎认为是优先级比较低的资源（图片）、服务器不可用、超过浏览器的并发请求的最大连接数（Chrome的最大并发连接数为6）.Stalled 从HTTP连接建立到请求能够被发出送出去(真正传输数据)之间的时间花费。包含用于处理代理的时间，如果有已经建立好的连接，这个时间还包括等待已建立连接被复用的时间。Proxy Negotiation 与代理服务器连接的时间花费。DNS Lookup 执行DNS查询的时间。网页上每一个新的域名都要经过一个DNS查询。第二次访问浏览器有缓存的话，则这个时间为0。Initial Connection / Connecting 建立连接的时间花费，包含了TCP握手及重试时间。SSL 完成SSL握手的时间花费。Request sent 发起请求的时间。Waiting (Time to first byte (TTFB)) 是最初的网络请求被发起到从服务器接收到第一个字节这段时间，它包含了TCP连接时间，发送HTTP请求时间和获得响应消息第一个字节的时间。Content Download 获取Response响应数据的时间花费。 TTFB这个部分的时间花费如果超过200ms，则应该考虑对网络进行性能优化了，可以参见网络性能优化方案及里面的相关参考文档。","categories":[{"name":"工具","slug":"工具","permalink":"http://duiliuliu.github.io/categories/工具/"}],"tags":[{"name":"浏览器","slug":"浏览器","permalink":"http://duiliuliu.github.io/tags/浏览器/"},{"name":"工具","slug":"工具","permalink":"http://duiliuliu.github.io/tags/工具/"}]},{"title":"python3网络爬虫开发实战_笔记","slug":"2018-04-01-python3网络爬虫开发实战_笔记","date":"2018-03-31T16:00:00.000Z","updated":"2019-03-03T15:14:32.867Z","comments":true,"path":"2018/04/01/2018-04-01-python3网络爬虫开发实战_笔记/","link":"","permalink":"http://duiliuliu.github.io/2018/04/01/2018-04-01-python3网络爬虫开发实战_笔记/","excerpt":"&lt;python3网络爬虫&gt;笔记","text":"&lt;python3网络爬虫&gt;笔记 python3网络爬虫开发实战_笔记 《python3网络爬虫开发实战》 –崔庆才著 原文出处 https://germey.gitbooks.io/python3webspider/content/ window平台相关笔记 开发环境配置 python 官网安装python3 Anaconda安装 清华大学镜像 会用到的包 pip安装 ： pip install 包名 源码安装 ： 通过git下载源代码，进入文件目录 执行 python3 setup.py install requests 请求包 selenium 是一个自动化测试包 需要浏览器驱动文件，并添加至环境变量 ChromeDriver selenium用来驱动Chrome浏览器的驱动程序 GeckoDriver selenium用来驱动Firefox浏览器的驱动程序 PhantomJS 是一个无界面的、可脚本编程的webkit浏览器引擎 api接口说明 aiohttp 异步H请求 pip install aiohttp 解析库 lxml 解析html和xml的库，支持xpath，解析效率高效 pip install lxml beautifulsoup 解析html和xml的库 pip install beautifulsoup pyquery 同样强大的网页解析工具 pip install pyquery tesserocr OCR 即Option Character Recognition,光学识别符。tesserocr是python的一个OCR识别库，但其实是对tesseract的封装，所以也需要安装tesseract。 pip install 。。。。 web库 flask 是一个轻量级的文本服务程序 pip install flask测试123456789101112from flask import Flaskapp = Flask(__name__)@app.route(&quot;/&quot;)def hello(): return &quot;hello world&quot;if __name__ == &quot;__main__&quot;: app.run()``` * tornado 是一个支持异步的web框架，通过使用非阻塞I/O流，它可以支持成千上万的开放连接，效率非常高 `pip install tornado`&lt;br&gt;测试 import tornado.ioloopimport tornado.web class MainHandler(tornado.web.RequestHandler): def get(self): self.write(&quot;hello world&quot;) def make_app(): return tornado.web.Application([ (r&quot;/&quot;,MainHandler), ]) if name == “main“: app = make_app() app.listen(8888) tornado.ioloop.IOloop.current().start() 12345678910111213141516 * App爬取相关的库 * [Charles](https://www.charlesproxy.com/download) 是一个网络抓包工具，相比Fiddler，功能更加强大 &lt;br&gt;注: 抓https需要安装证书 * mitmproxy 是一个支持http和https的抓包程序，类似Fiddler、Charles的功能，不过它通过控制台的形式操作 * mitmdump 它是mitmproxy的命令行接口，可以利用它来对接python脚本 * mitmweb 是一个web程序，可以通过它清除的观察mitmproxy捕获的请求 &lt;br&gt;`pip install mitmproxy` 或 https://github.com/mitmproxy/mitmproxy/releases/ &lt;br&gt;注: 抓https需要安装证书 * [Appium](https://github.com/appium/appium-desktop/releases) 是移动端的自动化测试工具，类似于前面所说的Selenium#### `数据读写`* 按照换行将question、 author、 answer写入文本整体以50个&apos;=&apos;分隔 ``` with open(&apos;explore.txt&apos;, &apos;a&apos;, encoding=&apos;utf-8&apos;) as file: file.write(&apos;\\n&apos;.join([question, author, answer])) file.write(&apos;\\n&apos; + &apos;=&apos; * 50 + &apos;\\n&apos;) json数据需要用双引号包围，不能使用单引号，若使用如下形式，则会出现错误： 123456789101112import jsonstr = &apos;&apos;&apos;[&#123; &apos;name&apos;: &apos;Bob&apos;, &apos;gender&apos;: &apos;male&apos;, &apos;birthday&apos;: &apos;1992-10-18&apos;&#125;]&apos;&apos;&apos;data = json.loads(str)&gt;&gt;&gt;json.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 3 column 5 (char 8) 因为这里数据用单引号来包围，loads()方法解析失败 csv文件的读写 12345678import csv with open(&apos;data.csv&apos;, &apos;w&apos;) as csvfile: writer = csv.writer(csvfile) writer.writerow([&apos;id&apos;, &apos;name&apos;, &apos;age&apos;]) writer.writerow([&apos;10001&apos;, &apos;Mike&apos;, 20]) writer.writerow([&apos;10002&apos;, &apos;Bob&apos;, 22]) writer.writerow([&apos;10003&apos;, &apos;Jordan&apos;, 21]) 对于写入文件后会出现空行的解决 open(&#39;data.csv&#39;,&#39;w&#39;,newline=&#39;&#39;) 如果想修改列与列之间的分隔符，可以传入delimiter参数，其代码如下：csv.writer(csvfile, delimiter=&#39; &#39;) writerows写入多行 字典读写 1234fieldnames = [&apos;id&apos;, &apos;name&apos;, &apos;age&apos;]writer = csv.DictWriter(csvfile, fieldnames=fieldnames)writer.writeheader()writer.writerow(&#123;&apos;id&apos;: &apos;10001&apos;, &apos;name&apos;: &apos;Mike&apos;, &apos;age&apos;: 20&#125;) 数据库 关系数据库 原子性(atomicity) 事务是一个不可分割的工作单位，事务中包括的诸操作要么全做，要么全不做 一致性(consistency) 事务必须使数据库从一个一致性状态变到另一个一致性状态。 隔离性(isolation) 一个事务的执行不能被其他事务干扰，即一个事物内部的操作及使用的数据 持久性(durability) 持续性也称永久性(permanence),指一个事务一旦提交，他对数据库中数据的改变就应该是永久性的。接下来的其他操作或故障不应该对其有任何影响 123456try: cursor.execute(sql) db.commit()except: db.rollback()db.close() 什么是事务，为何用事务？ 保证数据的一致性和完整性，例子：银行存钱 非关系型数据库 键值存储数据库：代表有Redis、Voldemort和Oracle BDB等。 列存储数据库：代表有Cassandra、HBase和Riak等。 文档型数据库：代表有CouchDB和MongoDB等。 图形数据库：代表有Neo4J、InfoGrid和Infinite Graph等。 mongodb insert_one()和insert_many()方法来分别插入单条记录和多条记录 find_one()或find()方法进行查询 count()计数、sort()排序、skip()偏移 create_index()索引操作 或者 collection.ensure_index(‘user_name’, unique=True) redis 数据类型： 键、字符串、列表(可重复)、有序集合、无序集合、散列 相应增删改查 利用Redis维护代理池，Scrapy-Redis分布式架构，利用Redis实现布隆过滤 异步抓取 ajax抓取 1234567891011121314var xmlhttp;if (window.XMLHttpRequest) &#123; // code for IE7+, Firefox, Chrome, Opera, Safari xmlhttp=new XMLHttpRequest();&#125; else &#123;// code for IE6, IE5 xmlhttp=new ActiveXObject(&quot;Microsoft.XMLHTTP&quot;);&#125;xmlhttp.onreadystatechange=function() &#123; if (xmlhttp.readyState==4 &amp;&amp; xmlhttp.status==200) &#123; document.getElementById(&quot;myDiv&quot;).innerHTML=xmlhttp.responseText; &#125;&#125;xmlhttp.open(&quot;POST&quot;,&quot;/ajax/&quot;,true);xmlhttp.send(); 随着网站的复杂度提升，越来越多的网站内容请求都是通过ajax请求的。 可通过浏览器开发者模式进行观察 XHR请求 或者 script请求 XHR是正常的ajax请求，而script是jsonp跨域访问的请求，目前微服务架构中需要跨域访问资源，故而将数据作为js对象进行传输 页面渲染 selenium 延时等待 time.sleep() 隐士等待 implicitly_wait() 显式等待12345678910from selenium import webdriverfrom selenium.webdriver.common.by import Byfrom selenium.webdriver.support.ui import WebDriverWaitfrom selenium.webdriver.support import expected_conditions as ECbrowser = webdriver.Chrome()browser.get(&apos;https://www.taobao.com/&apos;)wait = WebDriverWait(browser, 10)input = wait.until(EC.presence_of_element_located((By.ID, &apos;q&apos;)))button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, &apos;.btn-search&apos;)))print(input, button) 指定要查找的节点，然后指定一个最长等待时间，如果在规定时间里加载出了这个节点，就返回要查找的节点；如果到了规定时间依然没有加载出该节点，则抛出异常 前进与后退 1234browser.get(&apos;https://www.python.org/&apos;)browser.back()time.sleep(1)browser.forward() Splash 是一个JavaScript渲染服务，是一个带有HTTP API的轻量级浏览器，同时它对接了Python中的Twisted和QT库。利用它，我们同样可以实现动态渲染页面的抓取 利用Splash，我们可以实现如下功能： 异步方式处理多个网页渲染过程； 获取渲染后的页面的源代码或截图； 通过关闭图片渲染或者使用Adblock规则来加快页面渲染速度； 可执行特定的JavaScript脚本； 可通过Lua脚本来控制页面渲染过程； 获取渲染的详细过程并通过HAR（HTTP Archive）格式呈现。 接下来，我们来了解一下它的具体用法。 验证码 验证码识别 图形验证码利用tesserocr库识别简单图片 123456import tesserocrfrom PIL import Imageimage = Image.open(&apos;code.jpg&apos;)result = tesserocr.image_to_text(image)print(result) 当图片有多余的线条等干扰时，需要额外的处理，如：转灰度，二值化... **利用Image对象的convert()方法参数传入L,即可将图片转化为灰度图像**，如： 12image = image.convert(&apos;L&apos;)image.show() **传入1即可将图片进行二值化处理** 12image = image.convert(&apos;1&apos;)image.show() 还可以指定二值化的阙值，上面的方法采用的是默认阙值127，不过我们不能直接转化原图，要将原图转化为灰度图像，然后在制定二值化阙值。如： 123456789101112image = image.convert(&apos;L&apos;)#threshold代表二值化阙值threshold = 80table = []for i in range(256): if i &lt; threshold: table.append(0) else: table.append(1)image = image.point(table,&apos;1&apos;)image.show()","categories":[{"name":"python","slug":"python","permalink":"http://duiliuliu.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://duiliuliu.github.io/tags/python/"},{"name":"爬虫","slug":"爬虫","permalink":"http://duiliuliu.github.io/tags/爬虫/"}]},{"title":"python学习","slug":"python学习","date":"2018-03-12T16:00:00.000Z","updated":"2019-03-03T15:12:24.288Z","comments":true,"path":"2018/03/13/python学习/","link":"","permalink":"http://duiliuliu.github.io/2018/03/13/python学习/","excerpt":"","text":"Python 基础python 是一门比较流行的高级编程语言， 是一门解释型语言 解释型解释性语言通常把源程序编译成中间代码，然后用解释器把中间代码一条条翻译成目标机器代码，一条条执行。 Python的工作过程：先把代码编译成字节码，在对字节码解释执行。字节码在python虚拟机程序里对应的是PyCodeObject对象，pyc文件是字节码在磁盘上的表现形式。 编译型编译性语言写的程序在被执行之前，需要一个专门的编译过程，把程序编译成为机器语言的文件，比如exe文件，以后要运行的话就不用重新翻译了，直接使用编译的结果就行了（exe文件），因为翻译只做了一次，运行时不需要翻译，所以编译型语言的程序执行效率高 Java则是编译型语言。编译为字节码文件(.class)，然后会经jvm平台编译为目标机器代码 字节码 易跨平台迁移 机器码 运行快速 Python 简明约定 编码 通常使用 UDF-8 编码 Python2 遗留的习惯， 文件头部加入 # -*- coding=utf-8 -*- 代码格式 缩进一般使用四个空格进行缩进(javascript 规范为 2 个空格) 行宽每行代码一般不应过长，太长可能是设计有缺陷 引号单引号和双引号都可以用来表示一个字符串一般字典 key 使用单引号 空行模块级函数和类定义之间空两行；类成员函数之间空一行； 12345678910class A: def __init__(self): pass def hello(self): passdef main(): pass import 语句import 语句应该分行书写 123456789# 正确的写法import osimport sys# 不推荐的写法import sys,os# 正确的写法from subprocess import Popen, PIPE import 语句应该使用 absolute import 12345# 正确的写法from foo.bar import Bar# 不推荐的写法from ..bar import Bar 空格运算符前后空格 12345678910111213# 正确的写法i = i + 1submitted += 1x = x * 2 - 1hypot2 = x * x + y * yc = (a + b) * (a - b)# 不推荐的写法i=i+1submitted +=1x = x*2 - 1hypot2 = x*x + y*yc = (a+b) * (a-b) 换行使用反斜杠\\换行，二元运算符+ .等应出现在行末；长字符串也可以用此法换行 1234567session.query(MyTable).\\ filter_by(id=1).\\ one()print &apos;Hello, &apos;\\ &apos;%s %s!&apos; %\\ (&apos;Harry&apos;, &apos;Potter&apos;) docstring(文档注释)一般公共模块、函数、类、方法，都应该写 docstring 注释 “#”号后空一格，段落件用空行分开 12345# 块注释# 块注释## 块注释# 块注释 文档注释 文档注释以 “”” 开头和结尾, 首行不换行, 如有多行, 末行必需换行 1234567891011121314151617# -*- coding: utf-8 -*-&quot;&quot;&quot;Example docstrings.This module demonstrates documentation as specified by the `Google PythonStyle Guide`_. Docstrings may extend over multiple lines. Sections are createdwith a section header and a colon followed by a block of indented text.Example: Examples can be given using either the ``Example`` or ``Examples`` sections. Sections support any reStructuredText formatting, including literal blocks:: $ python example_google.pySection breaks are created by resuming unindented text. Section breaksare also implicitly created anytime a new section starts.&quot;&quot;&quot; 命名规范 模块模块名一般小写 123456# 正确的模块名import decoderimport html_parser# 不推荐的模块名import Decoder 类名类名使用驼峰(CamelCase)命名风格，首字母大写，私有类可用一个下划线开头 12345678class Farm(): passclass AnimalFarm(Farm): passclass _PrivateFarm(Farm): pass 将相关的类和顶级函数放在同一个模块里. 不像 Java, 没必要限制一个类一个模块. 函数函数名一律小写，如有多个单词，用下划线隔开 12345def run(): passdef run_with_env(): pass 变量名变量名尽量小写, 如有多个单词，用下划线隔开 123if __name__ == &apos;__main__&apos;: count = 0 school_name = &apos;&apos; 常量常量采用全大写，如有多个单词，使用下划线隔开 123MAX_CLIENT = 100MAX_CONNECTION = 1000CONNECTION_TIMEOUT = 600 数据类型 Numbers（数字） int（有符号整型） long（长整型[也可以代表八进制和十六进制]） float（浮点型） complex（复数） String（字符串） List（列表） Tuple（元组） Dictionary（字典） 语法结构 逻辑运算符 以下假设变量 a 为 10, b为 20: 运算符 逻辑表达式 描述 实例 and x and y 布尔”与” - 如果 x 为 False，x and y 返回 False，否则它返回 y 的计算值。 (a and b) 返回 20。 or x or y 布尔”或” - 如果 x 是非 0，它返回 x 的值，否则它返回 y 的计算值。 (a or b) 返回 10。 not not x 布尔”非” - 如果 x 为 True，返回 False 。如果 x 为 False，它返回 True。 not(a and b) 返回 False 成员运算符 运算符 描述 实例 in 如果在指定的序列中找到值返回True，否则返回False。 x 在 y序列中 , 如果x在y序列中返回True。 not in 如果在指定的序列中没有找到值返回True，否则返回False。 x 不在 y序列中 , 如果x不在y序列中返回True 身份运算符 身份运算符用于比较两个对象的存储单元 运算符 描述 实例 is is是判断两个标识符是不是引用自一个对象 x is y, 如果 id(x) 等于 id(y) , is 返回结果 1 is not is not是判断两个标识符是不是引用自不同对象 x is not y, 如果 id(x) 不等于 id(y). is not 返回结果 1 if分支语句，在python中没有switch语句 for循环语句for x in Array : do while特殊的是可以在最后添加else语句 变量、函数定义变量直接定义 12a = 3b = 2 函数定义使用def关键字，函数作用域使用缩进表示 12def fun(): pass 函数的参数可以赋以默认值，所以python中不需要函数重载 1234567def fun(param1=&quot;value1&quot;,param2=&quot;value2&quot;): print(&quot;params is &#123;&#125; and &#123;&#125;&quot;.format(param1,param2))fun(param2=&quot;传入的参数2&quot;)fun(&quot;传入参数一&quot;,&quot;传入参数二&quot;) Python 简单爬虫基础 python 网络库 urlliburllib 是 python 内置的 http 请求库，内置的主要是以下几个模块： urllib.request :请求模块 urllib.error :异常处理模块 urllib.parse :url解析模块 urllib.robotparer :robot.txt解析模块 1234import urllib.requestresponse = urllib.request.urlopen(&apos;http://www.baidu.com&apos;)# response得到的是网页的内容，bytes类型的数据，需要用utf-8转为字符串格式print(response.read().decode(&apos;utf-8&apos;)) 123456import urllib.parseimport urllib.request# 传入的data参数需要bytes类型data = bytes(urllib.parse.urlencode(&#123;&apos;word&apos;: &apos;hello&apos;&#125;), encoding=&apos;utf8&apos;)response = urllib.request.urlopen(&apos;http://httpbin.org/post&apos;, data=data)print(response.read()) 1234567891011121314151617181920import urllib.requestimport urllib.parseimport urllib.errorimport socket#url = &apos;https://python.org/&apos;url = &apos;http://httbin.org/post&apos;data = bytes(urllib.parse.urlencode(&#123;&apos;hello&apos;:&apos;world&apos;&#125;),encoding = &apos;utf8&apos;)headers = &#123;&quot;User-Agent&quot;:&quot;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36&quot;&#125;req = urllib.request.Request(url,headers = headers,data = data,method = &apos;POST&apos;)try: res = urllib.request.urlopen(req,timeout = 1) print(res.read().decode(&apos;utf-8&apos;)) print(&apos;OJBK&apos;)except urllib.error.URLError as e: if isinstance(e.reason,socket.timeout): print(&apos;TIMEOUT&apos;) Python 网络库 requests 发送请求 使用 Requests 发送网络请求非常简单。 一开始要导入 Requests 模块： &gt;&gt;&gt; import requests &gt;&gt;&gt; 然后，尝试获取某个网页。本例子中，我们来获取 Github 的公共时间线： &gt;&gt;&gt; r = requests.get(&apos;https://api.github.com/events&apos;) &gt;&gt;&gt; 现在，我们有一个名为 r 的 Response 对象。我们可以从这个对象中获取所有我们想要的信息。 Requests 简便的 API 意味着所有 HTTP 请求类型都是显而易见的。例如，你可以这样发送一个 HTTP POST 请求： &gt;&gt;&gt; r = requests.post(&apos;http://httpbin.org/post&apos;, data = {&apos;key&apos;:&apos;value&apos;}) &gt;&gt;&gt; 漂亮，对吧？那么其他 HTTP 请求类型：PUT，DELETE，HEAD 以及 OPTIONS 又是如何的呢？都是一样的简单： &gt;&gt;&gt; r = requests.put(&apos;http://httpbin.org/put&apos;, data = {&apos;key&apos;:&apos;value&apos;}) &gt;&gt;&gt; r = requests.delete(&apos;http://httpbin.org/delete&apos;) &gt;&gt;&gt; r = requests.head(&apos;http://httpbin.org/get&apos;) &gt;&gt;&gt; r = requests.options(&apos;http://httpbin.org/get&apos;) &gt;&gt;&gt; 都很不错吧，但这也仅是 Requests 的冰山一角呢。 传递 URL 参数 你也许经常想为 URL 的查询字符串(query string)传递某种数据。如果你是手工构建 URL，那么数据会以键/值对的形式置于 URL 中，跟在一个问号的后面。例如， httpbin.org/get?key=val。 Requests 允许你使用 params 关键字参数，以一个字符串字典来提供这些参数。举例来说，如果你想传递 key1=value1 和 key2=value2 到 httpbin.org/get ，那么你可以使用如下代码： &gt;&gt;&gt; payload = {&apos;key1&apos;: &apos;value1&apos;, &apos;key2&apos;: &apos;value2&apos;} &gt;&gt;&gt; r = requests.get(&quot;http://httpbin.org/get&quot;, params=payload) &gt;&gt;&gt; 通过打印输出该 URL，你能看到 URL 已被正确编码： &gt;&gt;&gt; print(r.url) &gt;&gt;&gt; http://httpbin.org/get?key2=value2&amp;key1=value1 &gt;&gt;&gt; 注意字典里值为 None 的键都不会被添加到 URL 的查询字符串里。 你还可以将一个列表作为值传入： &gt;&gt;&gt; payload = {&apos;key1&apos;: &apos;value1&apos;, &apos;key2&apos;: [&apos;value2&apos;, &apos;value3&apos;]} &gt;&gt;&gt; r = requests.get(&apos;http://httpbin.org/get&apos;, params=payload) &gt;&gt;&gt; print(r.url) &gt;&gt;&gt; http://httpbin.org/get?key1=value1&amp;key2=value2&amp;key2=value3 &gt;&gt;&gt; 响应内容 &gt;&gt;&gt; 我们能读取服务器响应的内容。再次以 GitHub 时间线为例： &gt;&gt;&gt; import requests &gt;&gt;&gt; r = requests.get(&apos;https://api.github.com/events&apos;) &gt;&gt;&gt; r.text &gt;&gt;&gt; u&apos;[{&quot;repository&quot;:{&quot;open_issues&quot;:0,&quot;url&quot;:&quot;https://github.com/... &gt;&gt;&gt; Requests 会自动解码来自服务器的内容。大多数 unicode 字符集都能被无缝地解码。 请求发出后，Requests 会基于 HTTP 头部对响应的编码作出有根据的推测。当你访问 r.text 之时，Requests 会使用其推测的文本编码。你可以找出 Requests 使用了什么编码，并且能够使用 r.encoding 属性来改变它： &gt;&gt;&gt; r.encoding &gt;&gt;&gt; &apos;utf-8&apos; &gt;&gt;&gt; r.encoding = &apos;ISO-8859-1&apos; &gt;&gt;&gt; 如果你改变了编码，每当你访问 r.text ，Request 都将会使用 r.encoding 的新值。你可能希望在使用特殊逻辑计算出文本的编码的情况下来修改编码。比如 HTTP 和 XML 自身可以指定编码。这样的话，你应该使用 r.content 来找到编码，然后设置 r.encoding 为相应的编码。这样就能使用正确的编码解析 r.text 了。 在你需要的情况下，Requests 也可以使用定制的编码。如果你创建了自己的编码，并使用 codecs 模块进行注册，你就可以轻松地使用这个解码器名称作为 r.encoding 的值， 然后由 Requests 来为你处理编码。 二进制响应内容 你也能以字节的方式访问请求响应体，对于非文本请求： &gt;&gt;&gt; r.content &gt;&gt;&gt; b&apos;[{&quot;repository&quot;:{&quot;open_issues&quot;:0,&quot;url&quot;:&quot;https://github.com/... &gt;&gt;&gt; Requests 会自动为你解码 gzip 和 deflate 传输编码的响应数据。 例如，以请求返回的二进制数据创建一张图片，你可以使用如下代码： &gt;&gt;&gt; from PIL import Image &gt;&gt;&gt; from io import BytesIO &gt;&gt;&gt; i = Image.open(BytesIO(r.content)) &gt;&gt;&gt; JSON 响应内容 &gt;&gt;&gt; Requests 中也有一个内置的 JSON 解码器，助你处理 JSON 数据： &gt;&gt;&gt; import requests &gt;&gt;&gt; r = requests.get(&apos;https://api.github.com/events&apos;) &gt;&gt;&gt; r.json() &gt;&gt;&gt; [{u&apos;repository&apos;: {u&apos;open_issues&apos;: 0, u&apos;url&apos;: &apos;https://github.com/... &gt;&gt;&gt; 如果 JSON 解码失败， r.json() 就会抛出一个异常。例如，响应内容是 401 (Unauthorized)，尝试访问 r.json() 将会抛出 ValueError: No JSON object could be decoded 异常。 需要注意的是，成功调用 r.json() 并不意味着响应的成功。有的服务器会在失败的响应中包含一个 JSON 对象（比如 HTTP 500 的错误细节）。这种 JSON 会被解码返回。要检查请求是否成功，请使用 r.raise_for_status() 或者检查 r.status_code 是否和你的期望相同。 原始响应内容 在罕见的情况下，你可能想获取来自服务器的原始套接字响应，那么你可以访问 r.raw。 如果你确实想这么干，那请你确保在初始请求中设置了 stream=True。具体你可以这么做： &gt;&gt;&gt; r = requests.get(&apos;https://api.github.com/events&apos;, stream=True) &gt;&gt;&gt; r.raw &gt;&gt;&gt; &lt;requests.packages.urllib3.response.HTTPResponse object at 0x101194810&gt; &gt;&gt;&gt; r.raw.read(10) &gt;&gt;&gt; &apos;\\x1f\\x8b\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x03&apos; &gt;&gt;&gt; 但一般情况下，你应该以下面的模式将文本流保存到文件： with open(filename, &apos;wb&apos;) as fd: for chunk in r.iter_content(chunk_size): fd.write(chunk) 使用 Response.iter_content 将会处理大量你直接使用 Response.raw 不得不处理的。 当流下载时，上面是优先推荐的获取内容方式。 Note that chunk_size can be freely adjusted to a number that may better fit your use cases. 定制请求头 如果你想为请求添加 HTTP 头部，只要简单地传递一个 dict 给 headers 参数就可以了。 例如，在前一个示例中我们没有指定 content-type: &gt;&gt;&gt; url = &apos;https://api.github.com/some/endpoint&apos; &gt;&gt;&gt; headers = {&apos;user-agent&apos;: &apos;my-app/0.0.1&apos;} &gt;&gt;&gt; r = requests.get(url, headers=headers) &gt;&gt;&gt; 注意: 定制 header 的优先级低于某些特定的信息源， 如果在 .netrc 中设置了用户认证信息，使用 headers= 设置的授权就不会生效。而如果设置了 auth= 参数，.netrc 的设置就无效了。 如果被重定向到别的主机，授权 header 就会被删除。 代理授权 header 会被 URL 中提供的代理身份覆盖掉。 在我们能判断内容长度的情况下，header 的 Content-Length 会被改写。 更进一步讲，Requests 不会基于定制 header 的具体情况改变自己的行为。只不过在最后的请求中，所有的 header 信息都会被传递进去。 注意: 所有的 header 值必须是 string、bytestring 或者 unicode。尽管传递 unicode header 也是允许的，但不建议这样做。 更加复杂的 POST 请求 通常，你想要发送一些编码为表单形式的数据——非常像一个 HTML 表单。要实现这个，只需简单地传递一个字典给 data 参数。你的数据字典在发出请求时会自动编码为表单形式： &gt;&gt;&gt; payload = {&apos;key1&apos;: &apos;value1&apos;, &apos;key2&apos;: &apos;value2&apos;} &gt;&gt;&gt; r = requests.post(&quot;http://httpbin.org/post&quot;, data=payload) &gt;&gt;&gt; print(r.text) &gt;&gt;&gt; { &gt;&gt;&gt; ... &gt;&gt;&gt; &quot;form&quot;: { &quot;key2&quot;: &quot;value2&quot;, &quot;key1&quot;: &quot;value1&quot; }, ... } 你还可以为 data 参数传入一个元组列表。在表单中多个元素使用同一 key 的时候，这种方式尤其有效： &gt;&gt;&gt; payload = ((&apos;key1&apos;, &apos;value1&apos;), (&apos;key1&apos;, &apos;value2&apos;)) &gt;&gt;&gt; r = requests.post(&apos;http://httpbin.org/post&apos;, data=payload) &gt;&gt;&gt; print(r.text) &gt;&gt;&gt; { &gt;&gt;&gt; ... &gt;&gt;&gt; &quot;form&quot;: { &quot;key1&quot;: [ &quot;value1&quot;, &quot;value2&quot; ] }, ... } 很多时候你想要发送的数据并非编码为表单形式的。如果你传递一个 string 而不是一个 dict，那么数据会被直接发布出去。 例如，Github API v3 接受编码为 JSON 的 POST/PATCH 数据： &gt;&gt;&gt; import json &gt;&gt;&gt; url = &apos;https://api.github.com/some/endpoint&apos; &gt;&gt;&gt; payload = {&apos;some&apos;: &apos;data&apos;} &gt;&gt;&gt; r = requests.post(url, data=json.dumps(payload)) &gt;&gt;&gt; 此处除了可以自行对 dict 进行编码，你还可以使用 json 参数直接传递，然后它就会被自动编码。这是 2.4.2 版的新加功能： &gt;&gt;&gt; url = &apos;https://api.github.com/some/endpoint&apos; &gt;&gt;&gt; payload = {&apos;some&apos;: &apos;data&apos;} &gt;&gt;&gt; r = requests.post(url, json=payload) &gt;&gt;&gt; POST 一个多部分编码(Multipart-Encoded)的文件 &gt;&gt;&gt; Requests 使得上传多部分编码文件变得很简单： &gt;&gt;&gt; url = &apos;http://httpbin.org/post&apos; &gt;&gt;&gt; files = {&apos;file&apos;: open(&apos;report.xls&apos;, &apos;rb&apos;)} &gt;&gt;&gt; r = requests.post(url, files=files) &gt;&gt;&gt; r.text &gt;&gt;&gt; { &gt;&gt;&gt; ... &gt;&gt;&gt; &quot;files&quot;: { &quot;file&quot;: &quot;&lt;censored...binary...data&gt;&quot; }, ... } 你可以显式地设置文件名，文件类型和请求头： &gt;&gt;&gt; url = &apos;http://httpbin.org/post&apos; &gt;&gt;&gt; files = {&apos;file&apos;: (&apos;report.xls&apos;, open(&apos;report.xls&apos;, &apos;rb&apos;), &apos;application/vnd.ms-excel&apos;, {&apos;Expires&apos;: &apos;0&apos;})} &gt;&gt;&gt; r = requests.post(url, files=files) &gt;&gt;&gt; r.text &gt;&gt;&gt; { &gt;&gt;&gt; ... &gt;&gt;&gt; &quot;files&quot;: { &quot;file&quot;: &quot;&lt;censored...binary...data&gt;&quot; }, ... } 如果你想，你也可以发送作为文件来接收的字符串： &gt;&gt;&gt; url = &apos;http://httpbin.org/post&apos; &gt;&gt;&gt; files = {&apos;file&apos;: (&apos;report.csv&apos;, &apos;some,data,to,send\\nanother,row,to,send\\n&apos;)} &gt;&gt;&gt; r = requests.post(url, files=files) &gt;&gt;&gt; r.text &gt;&gt;&gt; { &gt;&gt;&gt; ... &gt;&gt;&gt; &quot;files&quot;: { &quot;file&quot;: &quot;some,data,to,send\\\\nanother,row,to,send\\\\n&quot; }, ... } 如果你发送一个非常大的文件作为 multipart/form-data 请求，你可能希望将请求做成数据流。默认下 requests 不支持, 但有个第三方包 requests-toolbelt 是支持的。你可以阅读 toolbelt 文档 来了解使用方法。 在一个请求中发送多文件参考 高级用法 一节。 警告 我们强烈建议你用二进制模式(binary mode)打开文件。这是因为 Requests 可能会试图为你提供 Content-Length header，在它这样做的时候，这个值会被设为文件的字节数（bytes）。如果用文本模式(text mode)打开文件，就可能会发生错误。 响应状态码 我们可以检测响应状态码： &gt;&gt;&gt; r = requests.get(&apos;http://httpbin.org/get&apos;) &gt;&gt;&gt; r.status_code &gt;&gt;&gt; 200 &gt;&gt;&gt; 为方便引用，Requests 还附带了一个内置的状态码查询对象： &gt;&gt;&gt; r.status_code == requests.codes.ok &gt;&gt;&gt; True &gt;&gt;&gt; 如果发送了一个错误请求(一个 4XX 客户端错误，或者 5XX 服务器错误响应)，我们可以通过 Response.raise_for_status() 来抛出异常： &gt;&gt;&gt; bad_r = requests.get(&apos;http://httpbin.org/status/404&apos;) &gt;&gt;&gt; bad_r.status_code &gt;&gt;&gt; 404 &gt;&gt;&gt; bad_r.raise_for_status() &gt;&gt;&gt; Traceback (most recent call last): &gt;&gt;&gt; File &quot;requests/models.py&quot;, line 832, in raise_for_status raise http_error requests.exceptions.HTTPError: 404 Client Error 但是，由于我们的例子中 r 的 status_code 是 200 ，当我们调用 raise_for_status() 时，得到的是： &gt;&gt;&gt; r.raise_for_status() &gt;&gt;&gt; None &gt;&gt;&gt; 一切都挺和谐哈。 响应头 我们可以查看以一个 Python 字典形式展示的服务器响应头： &gt;&gt;&gt; r.headers &gt;&gt;&gt; { &apos;content-encoding&apos;: &apos;gzip&apos;, &apos;transfer-encoding&apos;: &apos;chunked&apos;, &apos;connection&apos;: &apos;close&apos;, &apos;server&apos;: &apos;nginx/1.0.4&apos;, &apos;x-runtime&apos;: &apos;148ms&apos;, &apos;etag&apos;: &apos;&quot;e1ca502697e5c9317743dc078f67693f&quot;&apos;, &apos;content-type&apos;: &apos;application/json&apos; } 但是这个字典比较特殊：它是仅为 HTTP 头部而生的。根据 RFC 2616， HTTP 头部是大小写不敏感的。 因此，我们可以使用任意大写形式来访问这些响应头字段： &gt;&gt;&gt; r.headers[&apos;Content-Type&apos;] &gt;&gt;&gt; &apos;application/json&apos; &gt;&gt;&gt; r.headers.get(&apos;content-type&apos;) &gt;&gt;&gt; &apos;application/json&apos; &gt;&gt;&gt; 它还有一个特殊点，那就是服务器可以多次接受同一 header，每次都使用不同的值。但 Requests 会将它们合并，这样它们就可以用一个映射来表示出来，参见 RFC 7230: A recipient MAY combine multiple header fields with the same field name into one “field-name: field-value” pair, without changing the semantics of the message, by appending each subsequent field value to the combined field value in order, separated by a comma. 接收者可以合并多个相同名称的 header 栏位，把它们合为一个 “field-name: field-value” 配对，将每个后续的栏位值依次追加到合并的栏位值中，用逗号隔开即可，这样做不会改变信息的语义。 Cookie 如果某个响应中包含一些 cookie，你可以快速访问它们： &gt;&gt;&gt; url = &apos;http://example.com/some/cookie/setting/url&apos; &gt;&gt;&gt; r = requests.get(url) &gt;&gt;&gt; r.cookies[&apos;example_cookie_name&apos;] &gt;&gt;&gt; &apos;example_cookie_value&apos; &gt;&gt;&gt; 要想发送你的 cookies 到服务器，可以使用 cookies 参数： &gt;&gt;&gt; url = &apos;http://httpbin.org/cookies&apos; &gt;&gt;&gt; cookies = dict(cookies_are=&apos;working&apos;) &gt;&gt;&gt; r = requests.get(url, cookies=cookies) &gt;&gt;&gt; r.text &gt;&gt;&gt; &apos;{&quot;cookies&quot;: {&quot;cookies_are&quot;: &quot;working&quot;}}&apos; &gt;&gt;&gt; Cookie 的返回对象为 RequestsCookieJar，它的行为和字典类似，但接口更为完整，适合跨域名跨路径使用。你还可以把 Cookie Jar 传到 Requests 中： &gt;&gt;&gt; jar = requests.cookies.RequestsCookieJar() &gt;&gt;&gt; jar.set(&apos;tasty_cookie&apos;, &apos;yum&apos;, domain=&apos;httpbin.org&apos;, path=&apos;/cookies&apos;) &gt;&gt;&gt; jar.set(&apos;gross_cookie&apos;, &apos;blech&apos;, domain=&apos;httpbin.org&apos;, path=&apos;/elsewhere&apos;) &gt;&gt;&gt; url = &apos;http://httpbin.org/cookies&apos; &gt;&gt;&gt; r = requests.get(url, cookies=jar) &gt;&gt;&gt; r.text &gt;&gt;&gt; &apos;{&quot;cookies&quot;: {&quot;tasty_cookie&quot;: &quot;yum&quot;}}&apos; &gt;&gt;&gt; 重定向与请求历史 &gt;&gt;&gt; 默认情况下，除了 HEAD, Requests 会自动处理所有重定向。 可以使用响应对象的 history 方法来追踪重定向。 Response.history 是一个 Response 对象的列表，为了完成请求而创建了这些对象。这个对象列表按照从最老到最近的请求进行排序。 例如，Github 将所有的 HTTP 请求重定向到 HTTPS： &gt;&gt;&gt; r = requests.get(&apos;http://github.com&apos;) &gt;&gt;&gt; r.url &gt;&gt;&gt; &apos;https://github.com/&apos; &gt;&gt;&gt; r.status_code &gt;&gt;&gt; 200 &gt;&gt;&gt; r.history &gt;&gt;&gt; [&lt;Response [301]&gt;] &gt;&gt;&gt; 如果你使用的是 GET、OPTIONS、POST、PUT、PATCH 或者 DELETE，那么你可以通过 allow_redirects 参数禁用重定向处理： &gt;&gt;&gt; r = requests.get(&apos;http://github.com&apos;, allow_redirects=False) &gt;&gt;&gt; r.status_code &gt;&gt;&gt; 301 &gt;&gt;&gt; r.history &gt;&gt;&gt; [] &gt;&gt;&gt; 如果你使用了 HEAD，你也可以启用重定向： &gt;&gt;&gt; r = requests.head(&apos;http://github.com&apos;, allow_redirects=True) &gt;&gt;&gt; r.url &gt;&gt;&gt; &apos;https://github.com/&apos; &gt;&gt;&gt; r.history &gt;&gt;&gt; [&lt;Response [301]&gt;] &gt;&gt;&gt; 超时 &gt;&gt;&gt; 你可以告诉 requests 在经过以 timeout 参数设定的秒数时间之后停止等待响应。基本上所有的生产代码都应该使用这一参数。如果不使用，你的程序可能会永远失去响应： &gt;&gt;&gt; requests.get(&apos;http://github.com&apos;, timeout=0.001) &gt;&gt;&gt; Traceback (most recent call last): &gt;&gt;&gt; File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt; &gt;&gt;&gt; requests.exceptions.Timeout: HTTPConnectionPool(host=&apos;github.com&apos;, port=80): Request timed out. (timeout=0.001) &gt;&gt;&gt; 注意 &gt;&gt;&gt; timeout 仅对连接过程有效，与响应体的下载无关。 timeout 并不是整个下载响应的时间限制，而是如果服务器在 timeout 秒内没有应答，将会引发一个异常（更精确地说，是在 timeout 秒内没有从基础套接字上接收到任何字节的数据时）If no timeout is specified explicitly, requests do not time out. 错误与异常 遇到网络问题（如：DNS 查询失败、拒绝连接等）时，Requests 会抛出一个 ConnectionError 异常。 如果 HTTP 请求返回了不成功的状态码， Response.raise_for_status() 会抛出一个 HTTPError 异常。 若请求超时，则抛出一个 Timeout 异常。 若请求超过了设定的最大重定向次数，则会抛出一个 TooManyRedirects 异常。 所有 Requests 显式抛出的异常都继承自 requests.exceptions.RequestException 。 Python 网页解析库 bs4 下面的一段 HTML 代码将作为例子被多次用到.这是 爱丽丝梦游仙境的 的一段内容(以后内容中简称为 爱丽丝 的文档): html_doc = &quot;&quot;&quot; \\&lt;html&gt;\\&lt;head&gt;\\&lt;title&gt;The Dormouse&apos;s story\\&lt;/title&gt;\\&lt;/head&gt; \\&lt;body&gt; \\&lt;p class=&quot;title&quot;&gt;\\&lt;b&gt;The Dormouse&apos;s story\\&lt;/b&gt;\\&lt;/p&gt; \\&lt;p class=&quot;story&quot;&gt;Once upon a time there were three little sisters; and their names were \\&lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;Elsie\\&lt;/a&gt;, \\&lt;a href=&quot;http://example.com/lacie&quot; class=&quot;sister&quot; id=&quot;link2&quot;&gt;Lacie\\&lt;/a&gt; and \\&lt;a href=&quot;http://example.com/tillie&quot; class=&quot;sister&quot; id=&quot;link3&quot;&gt;Tillie\\&lt;/a&gt;; and they lived at the bottom of a well.\\&lt;/p&gt; \\&lt;p class=&quot;story&quot;&gt;...\\&lt;/p&gt; &quot;&quot;&quot; 使用BeautifulSoup解析这段代码,能够得到一个 BeautifulSoup 的对象,并能按照标准的缩进格式的结构输出: from bs4 import BeautifulSoup soup = BeautifulSoup(html_doc) print(soup.prettify()) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586 # &lt;html&gt; # &lt;head&gt; # &lt;title&gt; # The Dormouse&apos;s story # &lt;/title&gt; # &lt;/head&gt; # &lt;body&gt; # &lt;p class=&quot;title&quot;&gt; # &lt;b&gt; # The Dormouse&apos;s story # &lt;/b&gt; # &lt;/p&gt; # &lt;p class=&quot;story&quot;&gt; # Once upon a time there were three little sisters; and their names were # &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt; # Elsie # &lt;/a&gt; # , # &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt; # Lacie # &lt;/a&gt; # and # &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link2&quot;&gt; # Tillie # &lt;/a&gt; # ; and they lived at the bottom of a well. # &lt;/p&gt; # &lt;p class=&quot;story&quot;&gt; # ... # &lt;/p&gt; # &lt;/body&gt; # &lt;/html&gt;几个简单的浏览结构化数据的方法: soup.title # &lt;title&gt;The Dormouse&apos;s story&lt;/title&gt; soup.title.name # u&apos;title&apos; soup.title.string # u&apos;The Dormouse&apos;s story&apos; soup.title.parent.name # u&apos;head&apos; soup.p # &lt;p class=&quot;title&quot;&gt;&lt;b&gt;The Dormouse&apos;s story&lt;/b&gt;&lt;/p&gt; soup.p[&apos;class&apos;] # u&apos;title&apos; soup.a # &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt; soup.find_all(&apos;a&apos;) # [&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;, # &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;, # &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;] soup.find(id=&quot;link3&quot;) # &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;从文档中找到所有a标签的链接: for link in soup.find_all(&apos;a&apos;): print(link.get(&apos;href&apos;)) # http://example.com/elsie # http://example.com/lacie # http://example.com/tillie从文档中获取所有文字内容: print(soup.get_text()) # The Dormouse&apos;s story # # The Dormouse&apos;s story # # Once upon a time there were three little sisters; and their names were # Elsie, # Lacie and # Tillie; # and they lived at the bottom of a well. # # ... Python 网页解析库 lxml菜鸟xpath http://www.runoob.com/xpath/xpath-tutorial.html 1234567#引入html解析库from lxml import html#解析为dom树结构htm = html.fromstring(html_doc)#利用xpath获取目标数据，返回的是一个list结果集htm.xpath(xpath_str) python 实战","categories":[{"name":"python","slug":"python","permalink":"http://duiliuliu.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://duiliuliu.github.io/tags/python/"}]}]}